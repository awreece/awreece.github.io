<!DOCTYPE html>
<html lang="en">
<head>
        <title>Code Arcana - Alex Reece</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="../theme/css/main.css" type="text/css" />
        <link href="../" type="application/atom+xml" rel="alternate" title="Code Arcana ATOM Feed" />
        

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="../css/ie.css"/>
                <script src="../js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="../css/ie6.css"/><![endif]-->

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="../index.html">Code Arcana </a></h1>
                <nav><ul>
                                    <li><a href="http://codearcana.com">Blog</a></li>
                                    <li><a href="http://codearcana.com">About Me</a></li>
                                                                                <li><a href="../">Archives</a></li>
                                </ul></nav>
        </header><!-- /#banner -->

                 <section id="content" class="body">
        <aside id="featured"><article>
                <h1 class="entry-title"><a href="../analysis-of-a-parallel-memory-allocator.html">Analysis of a Parallel Memory&nbsp;Allocator</a></h1>
                <footer class="post-info">
        <abbr class="published" title="2012-05-11T00:00:00">
                Fri 11 May 2012
        </abbr>

                <address class="vcard author">
                By <a class="url fn" href="../author/alex-reece.html">Alex Reece</a>
        </address>
        <p>In <a href="../category/performance.html">performance</a>. </p>
<p>tags: <a href="../tag/malloc.html">malloc</a></p></p></footer><!-- /.post-info --><!-- /.post-info -->
                <h1>Background</h1>
<h2>Problem</h2>
<p>Many modern programs frequently use dynamic memory allocation. However, modern
programs increasingly are multithreaded and parallel to take advantage of
increasingly parallel processors. Unfortunately, this trend conflicts with the
fact that there is a single heap in most current programs. Consequently,
research into parallel memory allocators is topical and&nbsp;important.</p>
<h2>Solution?</h2>
<p>The simplest solution to ensuring correctness in a multithread memory allocator
is to use a global lock around the heap. Unfortunately, this has
<em>extremely</em> negative performance consequences and is almost never 
adopted by modern memory allocators. Modern memory allocators tend to adopt 
some form of the following 3 solutions:
<ul>
<li>
They partition the heap into logical arenas or chunks that handle large 
portions of the heap. This reduces contention on the global heap and 
heap data&nbsp;structures.
</li>
<li>
They use fine grained locking on individual slabs or slab&nbsp;classes.
</li>
<li>
They use thread local caches to provide a fast path that requires no&nbsp;locks.
</li>
</ul></p>
<h2>Modern memory&nbsp;allocators</h2>
<p><p>As I understand, the most popular modern parallel mallocs are 
<a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919"><tt>jemalloc</tt></a>, 
<a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html"><tt>tcmalloc</tt></a>, 
<a href="http://www.malloc.de/en/"><tt>ptmalloc</tt></a>, 
<a href="https://doors.gracenote.com/developer/open.html"><tt>concur</tt></a>, 
<a href="http://www.nedprod.com/programs/portable/nedmalloc/"><tt>nedmalloc</tt></a>
and <a href="http://www.cs.umass.edu/~emery/pubs/berger-asplos2000.pdf"><tt>hoard</tt></a>. 
Oracle did some 
<a href="http://developers.sun.com/solaris/articles/multiproc/multiproc.html">investigation</a> 
and I have taken a look at the internals of jemalloc, tcmalloc, concur, and hoard. 
As I&nbsp;understand:</p>
<ul><li><tt>tcmalloc</tt> uses a global slab allocator with thread local caches to avoid&nbsp;contention</li>
    <li><tt>hoard</tt> uses different arenas and assigns superblocks to threads to avoid&nbsp;contention</li>
    <li><tt>jemalloc</tt> uses different arenas and thread local caches to avoid contention
and uses red black trees and an optimized slab allocator to avoid&nbsp;fragmentation</li>
<li><tt>concur</tt> uses different arenas and fine grained locking on size classes to avoid&nbsp;contention</li>
</ul>

<p></p>
<p>
One interesting characteristic of many of these memory allocators is that they
all tend to allocate memory from the system in chunks of about 1 to <span class="caps">4MB</span>.
Consequently, they tend to have an overhead of up to 2 to <span class="caps">4MB</span> per arena. Most
of them justify this overhead by pointing out that <span class="caps">2MB</span> of overhead is minimal
when the total application footprint can exceed <span class="caps">1GB</span> (in an application such as
firefox) and it is acceptable for an application to use <span class="caps">2MB</span> of heap when
modern computers routinely have several <span class="caps">GB</span> of&nbsp;<span class="caps">RAM</span>.
</p></p>
<p>
Another interesting characteristic of these memory allocators is they almost
never coallesce individual blocks (some do coallesce individual blocks). 
Instead, they use slab allocators and assume
allocation requests tend be of very similar sizes. In general, this follows
the general pattern of tolerating a moderate amount of memory overhead to
increase&nbsp;performance.
</p>

<h1>Approach</h1>
<h2>A simple modern memory&nbsp;allocator</h2>
<p><p>
In order to investigate and analyze the performance of a modern memory
allocator, I wrote a simplified memory allocator, <tt>ar_malloc</tt>, that 
uses many of the modern optimizations. <tt>ar_malloc</tt> is based quite
heavily on <tt>jemalloc</tt> but makes some simplifications. In order to keep 
the work manageable, <tt>ar_malloc</tt> makes the assumption that allocation 
requests are smaller than 1024 bytes. In addition, it uses slabs of a fixed 
size and never frees memory to the system (<tt>jemalloc</tt> uses variable sized
slabs to reduce memory&nbsp;overhead).
</p></p>
<h2>Testing a memory allocator&nbsp;##</h2>
<p><p>
In order to test <tt>ar_malloc</tt>, I constructed a test framework (based off a
test in the <tt>tcmalloc</tt> codebase) that spawns 
several threads that each randomly decide to allocate a random sized block or 
free a random block. This does not simulate the effect of actually using the blocks
and does not simulate a realistic workload, but it is still a useful
basis for investigation. I ran this test on a 16 core shared memory system and used
new initialization of malloc for each run to reduce the variance in run&nbsp;time.
</p></p>
<h1>Results</h1>
<h2>Comparision of <tt>ar_malloc</tt> to other&nbsp;solutions</h2>
<p><p>
We compared the performance of <tt>ar_malloc</tt>, <tt>ar_malloc</tt> with a global lock, 
and the libc malloc on the test described in the previous&nbsp;section.
</p>
<figure>
<img alt="Run time vs Number of threads" src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&amp;oid=4&amp;zx=1aneio5en2km" />
<figcaption>This is chart of test run time vs number of threads for a global locked malloc, <tt>ar_malloc</tt>, and libc malloc. As 
    you can see, the global lock solution is really bad.</figcaption>
</figure></p>
<figure>
    <img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&oid=14&zx=rgpgcr33f1ax" />
    <figcaption>This is chart of test run time vs number of threads for <tt>ar_malloc</tt> and libc malloc. As 
    you can see, <tt>ar_malloc</tt> is about 3 times faster than libc for even
    single threaded execution. </figcaption>
</figure>

<figure>
    <img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&oid=8&zx=ttz2qtfnzo60" />
    <figcaption>This is chart of test speedup vs number of threads for <tt>ar_malloc</tt> and libc malloc. As 
    you can see, <tt>ar_malloc</tt> exhibits linear speedup that scales cleanly with
    the number of threads, whereas libc scales only to about 8 threads. 
    </figcaption>
</figure>

<h2>Comparison of different&nbsp;configuration</h2>
<p><p>
I examined several different configurations of <tt>ar_malloc</tt>, specifically 
focusing on the number of arenas. We attempted to figure out the effect of and 
analyze the behavior of using different number of&nbsp;arenas.
</p></p>
<figure>
    <img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&oid=11&zx=fwaahh94nhlg" />
<figcaption>This is a chart of run time vs number of threads for different configurations of <tt>ar_malloc</tt>.
    As you can see, there appear to be two curves. We will call the lower one the &#8220;no contention&#8221; curve and the
    upper one the &#8220;contention&#8221; curve. You can see that the performance of a memory allocator moves from the &#8220;no contention&#8221;
    curve to the &#8220;contention&#8221; curve when the number of threads exceeds the number of arenas.
    </figcaption>
</figure>

<figure>
    <img src="https://docs.google.com/spreadsheet/oimg?key=0AjzaNgu-PE5_dDJJUnRCaXZueks1UTlQVXBxYlFsSXc&oid=13&zx=fhdbihufrx4u" />
    <figcaption>
    This is a chart of speedup vs number of threads for different configurations of <tt>ar_malloc</tt>. As you before, there are 
    two curves: the &#8220;no contention&#8221; line and the &#8220;contention&#8221; line. Again, the speedup of a memory allocator
    moves from the &#8220;no contention&#8221; line to the &#8220;contention&#8221; line when the number of threads exceeds the 
    number of arenas. It is important to note that the speedup is still mostly linear even when the number of arenas is far less
    than number of threads.
    </figcaption>
</figure>

<h1>Conclusion</h1>
<p>Over the course of this project, I have demonstrated that it is feasible to 
write a modern parallel memory allocator that performs quite favorably 
on random workloads. <tt>ar_malloc</tt> makes many simplifying assumptions,
but is just over 2000 lines of code, outperforms libc malloc by a factor
of 3, and demonstrates linear speedup that seems to scale very well with
the number of&nbsp;threads.</p>
<h1>Further&nbsp;Investigation</h1>
<p><p>
There are several routes for further investigation in parallel memory&nbsp;allocators.</p>
<p>The exisiting test framework allocates random sizes distributed
uniformly in the range 8, 1024. This almost certainly does not simulate 
realistic memory allocation patterns. An interesting further exploration could
use <tt>ar_malloc</tt> with real programs (either via static linking or LD_PRELOAD) 
or to investigate the actual memory distribution of a general&nbsp;program. 
</p>
<p>This investigation only examined the effect of different number of arenas.
A further exploration could examine the effect of thread local caches and fine
grained locking on the performance of <tt>ar_malloc</tt>.
</p></p>
        </article></aside><!-- /#featured -->
                        <h1>Other articles</h1>
                <hr />
                    <ol id="posts-list" class="hfeed">
                        <li><article class="hentry">
                <header>
                        <h1><a href="../introduction-to-using-profiling-tools.html" rel="bookmark" title="Permalink to Introduction to Using Profiling&nbsp;Tools">Introduction to Using Profiling&nbsp;Tools</a></h1>
                </header>

                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-02-26T00:00:00">
                Tue 26 February 2013
        </abbr>

                <address class="vcard author">
                By <a class="url fn" href="../author/alex-reece.html">Alex Reece</a>
        </address>
        <p>In <a href="../category/performance.html">performance</a>. </p>
<p>tags: <a href="../tag/profiling.html">profiling</a></p></p></footer><!-- /.post-info --><!-- /.post-info -->
                In this article, you will see several performance tools used to identify bottlenecks in a simple program.
                <a class="readmore" href="../introduction-to-using-profiling-tools.html">read more</a>
                </div><!-- /.entry-content -->
        </article></li>
                <li><article class="hentry">
                <header>
                        <h1><a href="../pai-mei-on-mac-osx-108.html" rel="bookmark" title="Permalink to Pai Mei on Mac <span class="caps">OSX</span>&nbsp;10.8">Pai Mei on Mac <span class="caps">OSX</span>&nbsp;10.8</a></h1>
                </header>

                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2012-10-28T00:00:00">
                Sun 28 October 2012
        </abbr>

                <address class="vcard author">
                By <a class="url fn" href="../author/alex-reece.html">Alex Reece</a>
        </address>
        <p>In <a href="../category/security.html">security</a>. </p>
<p>tags: <a href="../tag/mac-osx.html">mac osx</a><a href="../tag/reverse-engineering.html">reverse engineering</a></p></p></footer><!-- /.post-info --><!-- /.post-info -->
                <p><a href="https://github.com/OpenRCE/paimei">Pai Mei</a> is an open source windows reverse engineering framework. At one point, it was ported to Mac <span class="caps">OSX</span> but the project is not very actively maintained and the current instructions are quite lacking. This post hopes to offer some guidance and reduce some of the frustration involved in installing ...</p>
                <a class="readmore" href="../pai-mei-on-mac-osx-108.html">read more</a>
                </div><!-- /.entry-content -->
        </article></li>
                <li><article class="hentry">
                <header>
                        <h1><a href="../securing-and-exploiting-go-binaries.html" rel="bookmark" title="Permalink to Securing and Exploiting Go&nbsp;Binaries">Securing and Exploiting Go&nbsp;Binaries</a></h1>
                </header>

                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2012-05-06T00:00:00">
                Sun 06 May 2012
        </abbr>

                <address class="vcard author">
                By <a class="url fn" href="../author/alex-reece.html">Alex Reece</a>
        </address>
        <p>In <a href="../category/security.html">security</a>. </p>
<p>tags: <a href="../tag/golang.html">golang</a><a href="../tag/exploitation.html">exploitation</a></p></p></footer><!-- /.post-info --><!-- /.post-info -->
                I have spent some time over the past month or so trying to use Go binaries in a secure manner and trying to exploit Go binaries and I thought it would be useful if I talked a little bit about my journey.
                <a class="readmore" href="../securing-and-exploiting-go-binaries.html">read more</a>
                </div><!-- /.entry-content -->
        </article></li>
    </ol><!-- /#posts-list -->
</section><!-- /#content -->

        <aside id="sidebar">
                <div class="widget">
                        <h2>Categories</h2>
                        <ul>
                                                   <li ><a href="../category/performance.html">performance</a></li>
                                                   <li ><a href="../category/security.html">security</a></li>
                                                </ul>
                </div>
                        <div class="widget blogroll">
                        <h2>Blogroll</h2>
                        <ul>
                                                    <li><a href="http://ppp.cylab.cmu.edu/wordpress/">PPP Blog</a></li>
                                                    <li><a href="http://www.codinghorror.com/blog/">Coding Horror</a></li>
                                                    <li><a href="http://blog.regehr.org/">Embedded in Academia</a></li>
                                                </ul>
                </div><!-- /.blogroll -->
                                <div class="widget social">
                        <h2>Social</h2>
                        <ul>
                            <li><a href="../" rel="alternate">atom feed</a></li>
                            
                                                    <li><a href="https://twitter.com/awreece">twitter</a></li>
                                                    <li><a href="https://github.com/awreece">github</a></li>
                                                    <li><a href="https://plus.google.com/106589059588263736517/posts">google+</a></li>
                                                </ul>
                </div><!-- /.social -->
                </aside><!-- /#sidebar -->

        <footer id="footer" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://alexis.notmyidea.org/pelican/">pelican</a>, which takes great advantages of <a href="http://python.org">python</a>.
                </address><!-- /#about -->

                <p>The theme is «notmyidea-cms», a modified version of «notmyidea», the default theme.</p>
        </footer><!-- /#footer -->

    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    try {
        var pageTracker = _gat._getTracker("UA-40107691-1");
    pageTracker._trackPageview();
    } catch(err) {}</script>
</body>
</html>